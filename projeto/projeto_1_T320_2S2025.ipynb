{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto 1 - T320 (2S2025)\n",
        "\n",
        "### Instruções\n",
        "\n",
        "1. Quando você terminar os exercícios do projeto, vá até o menu do Jupyter ou Colab e selecione a opção para fazer download do notebook.\n",
        "    * Os notebooks tem extensão .ipynb.\n",
        "    * Este deve ser o arquivo que você irá entregar.\n",
        "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
        "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
        "2. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção para anexar arquivos à tarefa.\n",
        "3. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão consideradas.\n",
        "4. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
        "5. Todas as questões têm o mesmo peso.\n",
        "6. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Coloque os nomes dos integrantes do grupo no campo de texto abaixo.\n",
        "7. Você pode consultar todo o material de aula.\n",
        "8. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
        "9. Boa sorte!"
      ],
      "metadata": {
        "id": "NuFNIngFwW_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nomes e matrículas**:\n",
        "\n",
        "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
        "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
        "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
      ],
      "metadata": {
        "id": "fA-MANpFmds9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercícios"
      ],
      "metadata": {
        "id": "EJZhRywOmiZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) **Uso de classificador para detecção de símbolos de uma modulação digital**\n",
        "\n",
        "Neste exercício, você irá usar um classificador para detectar símbolos de uma modulação digital, a modulação 16QAM.\n",
        "\n",
        "\n",
        "1.1) Execute a célula abaixo e analise o resultado. A figura mostra símbolos ruidosos da modulação 16QAM, onde cada um dos quatro possíveis símbolos é considerado como uma classe diferente.\n",
        "\n",
        "**DICAS:**\n",
        "\n",
        "+ Notem que na célula de código abaixo, o conjunto de dados já está dividido em conjuntos de treinamento e validação."
      ],
      "metadata": {
        "id": "jl2afirb1oNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all necessary modules.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.special import erfc\n",
        "import seaborn as sns\n",
        "\n",
        "# Reset PN sequence generator.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Definition of function used to modulate.\n",
        "def modulate16QAM(bits):\n",
        "    # Conjunto de símbolos 16QAM (Gray coded) com energia média normalizada\n",
        "    symbols_16qam = [\n",
        "        -3-3j, -3-1j, -3+3j, -3+1j,\n",
        "        -1-3j, -1-1j, -1+3j, -1+1j,\n",
        "         3-3j,  3-1j,  3+3j,  3+1j,\n",
        "         1-3j,  1-1j,  1+3j,  1+1j\n",
        "    ]\n",
        "    ip = symbols_16qam[bits]\n",
        "    # Normalização: energia média de 16QAM é 10 → divide por sqrt(10)\n",
        "    symbol = (1.0/np.sqrt(10.0)) * ip\n",
        "    return symbol\n",
        "\n",
        "# Number of symbols to be transmitted.\n",
        "N = 1000000\n",
        "\n",
        "# Number of classes.\n",
        "numOfClasses = 16\n",
        "\n",
        "# Create Es/N0 vector.\n",
        "EsN0dB = 19 # in dB\n",
        "EsN0Lin = 10.0**(-(EsN0dB/10.0))\n",
        "\n",
        "# Modulate symbols and add noise.\n",
        "y = np.zeros((N, 1), dtype=complex)\n",
        "bit_16qam = np.zeros((N,), dtype=int)\n",
        "for i in range(0, N):\n",
        "\n",
        "    # Generate 16QAM symbols.\n",
        "    bit_16qam[i] = np.random.randint(0, 16)\n",
        "    # Modulate the binary stream into 16QAM symbols.\n",
        "    symbol = modulate16QAM(bit_16qam[i])\n",
        "\n",
        "    # Pass 16QAM symbols through AWGN channel.\n",
        "    noise = np.sqrt(EsN0Lin/2.0) * (np.random.randn() + 1j*np.random.randn())\n",
        "    y[i] = symbol + noise\n",
        "\n",
        "# Create the attribute matrix.\n",
        "# As the scikit-learn classes do not accept complex numbers, we split one complex number in its real and imaginary parts, then doubling the number of samples.\n",
        "X = np.c_[np.real(y), np.imag(y)]\n",
        "\n",
        "# Split array into random train and test subsets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, bit_16qam, test_size=0.3, stratify=bit_16qam, random_state=seed)\n",
        "\n",
        "# Plot the classes.\n",
        "plt.figure()\n",
        "for k in range(16):\n",
        "    idx = np.argwhere(bit_16qam == k)\n",
        "    plt.plot(np.real(y[idx.ravel()]), np.imag(y[idx.ravel()]), '.', markersize=4, label=f'Symbol {k}')\n",
        "\n",
        "plt.grid()\n",
        "plt.xlabel('InPhase')\n",
        "plt.ylabel('Quadrature')\n",
        "plt.title('16QAM Constellation')\n",
        "\n",
        "# Legenda fora do quadro (à direita)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=1, fontsize=7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "znvGvlDZ2UPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2 ) Neste item do exercício, treine um regressor Softmax com o conjunto de treinamento gerado no item anterior, calcule e imprima sua acurácia com o conjunto de validação.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Para que os próximos itens deste exercício funcionem corretamente, chame seu modelo de `model`."
      ],
      "metadata": {
        "id": "2WayFHCW3HuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "Pw7rUoGuBuHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3 ) Usando o modelo treinado no item anterior, plote as regiões de decisão deste classificador."
      ],
      "metadata": {
        "id": "5MG242PCB3jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "9GeREcBoCjpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4 ) Observe a figura com as regiões de decisão e responda: As regiões de decisão do classificador se assemelham às regiões do detector 16QAM ótimo? (**Justifique sua resposta**)\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "- Veja o conteúdo do blog a seguir: https://dsplog.com/2007/12/09/symbol-error-rate-for-16-qam/"
      ],
      "metadata": {
        "id": "FK-Z6Avdt2io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva sua resposta abaixo.</span>"
      ],
      "metadata": {
        "id": "rzKYwFXavvUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.5 ) Plote a matriz de confusão deste classificador para os exemplos do conjunto de validação."
      ],
      "metadata": {
        "id": "Hy8zELAZDF58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "uYy9dk6EDMoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.6 ) Analise a figura com as regiões de decisão, a matriz de confusão e responda: Por que o classificador não atinge 100% de acurácia, ou seja, não detecta corretamente todos os símbolos? (**Justifique sua resposta**)"
      ],
      "metadata": {
        "id": "CqYoxd85xPBL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva sua resposta abaixo.</span>"
      ],
      "metadata": {
        "id": "FT4TG4Iqxe4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.7 ) Analise a matriz de confusão e responda:\n",
        "\n",
        "+ Qual a acurácia deste classificador?\n",
        "+ Qual é o F1-score do classificador?\n",
        "+ Podemos afirmar que este é um classificador com boa capacidade de generalização?\n",
        "+ Se a taxa de erro de símbolo (symbol error rate - SER) é dada por: 1 - acurácia, qual a SER deste classificador?\n",
        "\n",
        "**Justifique suas respostas.**\n",
        "\n",
        "**DICAS**\n",
        "- Os calculos devem ser feitos com os valores da matriz de confusão."
      ],
      "metadata": {
        "id": "Go2oZCgoV50O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva sua resposta abaixo.</span>"
      ],
      "metadata": {
        "id": "BaMBcUUSqAb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.8 ) Neste ítem, você irá comparar a taxa de erro de símbolo obtida pelo classificador treinado com a taxa de erro de símbolo teórica da modulação 16QAM. Portanto, execute a célula de código abaixo e analise o resultado obtido.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Para que o código abaixo funcione corretamente, o nome do seu classificador treinado em um dos itens anteriores deve ser `model`.\n",
        "+ Esta simulação irá demorar um pouco, aguarde 30 minutos, em média."
      ],
      "metadata": {
        "id": "LxRzRAdKDr58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of symbols to be transmitted.\n",
        "N = 1000000\n",
        "\n",
        "# Sweep in Eb/N0 (dB) and convert to Es/N0 (dB) for M=16 (k = log2(M) = 4)\n",
        "EbN0dB = np.arange(-2, 16, 2)\n",
        "k = 4  # bits por símbolo na 16QAM\n",
        "EsN0dB = EbN0dB + 10*np.log10(k)  # Es/N0 = Eb/N0 + 10*log10(k)\n",
        "\n",
        "# Arrays for SER\n",
        "ser_simu = np.zeros((len(EbN0dB),))\n",
        "ser_theo = np.zeros((len(EbN0dB),))\n",
        "\n",
        "# Função de modulação 16QAM (Gray coded, energia normalizada: Es=1)\n",
        "def modulate16QAM(bits):\n",
        "    symbols_16qam = [\n",
        "        -3-3j, -3-1j, -3+3j, -3+1j,\n",
        "        -1-3j, -1-1j, -1+3j, -1+1j,\n",
        "         3-3j,  3-1j,  3+3j,  3+1j,\n",
        "         1-3j,  1-1j,  1+3j,  1+1j\n",
        "    ]\n",
        "    ip = symbols_16qam[bits]\n",
        "    return ip / np.sqrt(10.0)  # normalização para Es=1\n",
        "\n",
        "# Q-function\n",
        "from scipy.special import erfc\n",
        "def Q(x):\n",
        "    return 0.5*erfc(x/np.sqrt(2))\n",
        "\n",
        "# Loop de simulação\n",
        "for idx in range(len(EbN0dB)):\n",
        "    # Converta Es/N0 (dB) -> linear\n",
        "    EsN0Lin = 10.0**(EsN0dB[idx]/10.0)  # relação linear Es/N0\n",
        "    N0 = 1.0 / EsN0Lin                  # pois Es = 1 após normalização\n",
        "    errors = 0\n",
        "\n",
        "    for i in range(N):\n",
        "        # Símbolo aleatório 16QAM\n",
        "        bit_16qam = np.random.randint(0, 16)\n",
        "        symbol = modulate16QAM(bit_16qam)\n",
        "\n",
        "        # Canal AWGN\n",
        "        noise = np.sqrt(N0/2.0) * (np.random.randn() + 1j*np.random.randn())\n",
        "        y = symbol + noise\n",
        "\n",
        "        # Detector ML: escolhe o ponto da constelação mais próximo\n",
        "        # (distância euclidiana ao conjunto de 16 pontos)\n",
        "        min_dist = np.inf\n",
        "        detected_symbol = 0\n",
        "        for s in range(16):\n",
        "            ref = modulate16QAM(s)\n",
        "            d = np.abs(y - ref)\n",
        "            if d < min_dist:\n",
        "                min_dist = d\n",
        "                detected_symbol = s\n",
        "\n",
        "        # Contagem de erros de símbolo\n",
        "        if detected_symbol != bit_16qam:\n",
        "            errors += 1\n",
        "\n",
        "    # SER simulada\n",
        "    ser_simu[idx] = errors / N\n",
        "\n",
        "    # SER teórica para 16QAM (em Es/N0)\n",
        "    # Ps ≈ 3*Q( sqrt(Es/(5N0)) ) - (9/4)*Q^2( sqrt(Es/(5N0)) )\n",
        "    # Como Es/N0 = EsN0Lin, então:\n",
        "    arg = np.sqrt(EsN0Lin / 5.0)\n",
        "    ser_theo[idx] = 3.0*Q(arg) - (9.0/4.0)*(Q(arg)**2)\n",
        "\n",
        "    print(f'Eb/N0: {EbN0dB[idx]:>2} dB  |  SER simu: {ser_simu[idx]:.3e}  |  SER theo: {ser_theo[idx]:.3e}')\n",
        "\n",
        "# Plot (eixo em Eb/N0)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(EbN0dB, ser_theo, label='16QAM teórica')\n",
        "plt.plot(EbN0dB, ser_simu, 'ro', label='16QAM simulada')\n",
        "plt.xlabel('Eb/N0 [dB]')\n",
        "plt.ylabel('SER')\n",
        "plt.yscale('log')\n",
        "plt.grid(True, which='both')\n",
        "plt.title('16QAM detection over AWGN (SER vs Eb/N0)')\n",
        "plt.legend()\n",
        "plt.xlim([EbN0dB.min(), EbN0dB.max()])\n",
        "plt.ylim([1e-6, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rid9PovXD9Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.9 ) Após a análise dos resultados acima, podemos dizer que o classificador apresenta boa performance quando comparado com a curva da taxa de erro de símbolo teórica da modulação 16QAM? (**Justifique sua resposta**)"
      ],
      "metadata": {
        "id": "93lZtn1OE1bW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva sua resposta abaixo.</span>\n"
      ],
      "metadata": {
        "id": "tURt2MCMLaBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) **Exercício sobre classificação aplicada ao ***Churn*** de clientes em servições de telecomunicações.**\n",
        "\n",
        "Você sabia que atrair um novo cliente custa de cinco a sete vezes mais do que manter um já existente?\n",
        "\n",
        "Muitas vezes, os clientes ficam insatisfeitos com os serviços prestados e encerram o contrato ou assinatura. Essa rotatividade de clientes, ou `Churn`, (taxa de clientes ou assinantes que deixam de fazer negócios com uma empresa) afeta drasticamente as finanças das empresas de telecomunicações. Portanto, para reduzir a rotatividade de clientes, as empresas precisam prever quais clientes correm alto risco de encerrarem o contrato ou assinatura.\n",
        "\n",
        "Baseado nessas informações, vamos encontrar um modelo que ajude as empresas a prever a satisfação dos clientes, identificando se eles pretendem encerrar o contrato.\n",
        "\n",
        "O conjunto de dados que utilizaremos contém 20 atributos (i.e., colunas) que indicam as características dos clientes de uma empresa fictícia de telecomunicações que fornece serviços de telefone residencial e Internet na Califórnia.\n",
        "\n",
        "A coluna `Churn` (i.e., o rótulo) indica se o cliente encerrou o contrato ou assinatura no último mês ou não. A classe `No` inclui os clientes que não encerram o relaciomento com a empresa no último mês, enquanto a classe `Yes` contém os clientes que decidiram encerrar o relacionamento com a empresa. O objetivo da nossa análise é obter a relação entre os atributos do cliente e o *churn* (i.e., término do relaciomento). Notem, portanto, que este é um problema de classificação binária.\n",
        "\n",
        "Além da coluna/atributo `customerID`, o conjunto de dados contém outros 19 atributos, os quais podem ser agrupados em 3 grupos:\n",
        "\n",
        "**1 - Demographic Information**\n",
        "\n",
        "+ gender: Whether the client is a female or a male (Female, Male).\n",
        "+ SeniorCitizen: Whether the client is a senior citizen or not ( 0, 1).\n",
        "+ Partner: Whether the client has a partner or not (Yes, No).\n",
        "+ Dependents: Whether the client has dependents or not (Yes, No).\n",
        "\n",
        "**2 - Customer Account Information**\n",
        "\n",
        "+ tenure: Number of months the customer has stayed with the company (Multiple different numeric values).\n",
        "+ Contract: Indicates the customer’s current contract type (Month-to-Month, One year, Two year).\n",
        "+ PaperlessBilling: Whether the client has paperless billing or not (Yes, No).\n",
        "+ PaymentMethod: The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit Card (automatic)).\n",
        "+ MontlyCharges: The amount charged to the customer monthly (Multiple different numeric values).\n",
        "+ TotalCharges: The total amount charged to the customer (Multiple different numeric values).\n",
        "\n",
        "**3 - Services Information**\n",
        "\n",
        "+ PhoneService: Whether the client has a phone service or not (Yes, No).\n",
        "+ MultipleLines: Whether the client has multiple lines or not (No phone service, No, Yes).\n",
        "+ InternetServices: Whether the client is subscribed to Internet service with the company (DSL, Fiber optic, No)\n",
        "+ OnlineSecurity: Whether the client has online security or not (No internet service, No, Yes).\n",
        "+ OnlineBackup: Whether the client has online backup or not (No internet service, No, Yes).\n",
        "+ DeviceProtection: Whether the client has device protection or not (No internet service, No, Yes).\n",
        "+ TechSupport: Whether the client has tech support or not (No internet service, No, Yes).\n",
        "+ StreamingTV: Whether the client has streaming TV or not (No internet service, No, Yes).\n",
        "+ StreamingMovies: Whether the client has streaming movies or not (No internet service, No, Yes).\n",
        "\n",
        "#### Referências\n",
        "\n",
        "[1] 'End-to-end machine learning project: Telco customer churn', https://towardsdatascience.com/end-to-end-machine-learning-project-telco-customer-churn-90744a8df97d\n",
        "\n",
        "[2] 'Telco Customer Churn: Focused customer retention programs', https://www.kaggle.com/datasets/blastchar/telco-customer-churn?resource=download\n",
        "\n",
        "[3] 'Customer Churn (Marketing)', https://catalog.workshops.aws/canvas-immersion-day/en-US/1-use-cases/1-marketing\n",
        "\n",
        "[4] 'Telecom customer churn prediction', https://www.kaggle.com/code/bhartiprasad17/customer-churn-prediction\n",
        "\n",
        "[5] 'Telco customer churn (11.1.3+)', https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113\n",
        "\n",
        "[6] 'telco-customer-churn', https://www.openml.org/search?type=data&sort=runs&id=42178&status=active\n",
        "\n"
      ],
      "metadata": {
        "id": "Wq1TUWrBok1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1) Execute a célula abaixo para os módulos necessários e baixar o conjunto de dados. Na sequência, analise as linhas que serão impressas.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Após a execução bem sucedida da célula abaixo, você visualizará as 20 primeiras linhas da base de dados.\n",
        "+ A coluna `Churn` será o valor alvo (i.e., o rótulo). Os rótulos são os valores que o modelo é treinado para predizer."
      ],
      "metadata": {
        "id": "dOtFMog7BX42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importe todas os módulos necessários.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import urllib\n",
        "\n",
        "# Reseta o gerador de sequências pseudo aleatórias.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Baixa as bases de dados do dropbox.\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/xg2hzt0p8p3zsjd/telco_customer_churn.csv?dl=1', 'telco_customer_churn.csv')\n",
        "\n",
        "# Importa os arquivos CSV.\n",
        "df = pd.read_csv('./telco_customer_churn.csv')\n",
        "\n",
        "# Mostra as 20 primeiras linhas.\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "qhWl0ywyBdgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2) Execute a célula abaixo para realizar a limpeza dos dados.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para limpar a base de dados."
      ],
      "metadata": {
        "id": "TUWr2jQdBiBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Força a coluna 'TotalCharges' a ser do tipo numérico.\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Remove exemplos (i.e., linhas) com valores nulos.\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove a coluna 'customerID' pois ela é inútil para explicar se o cliente não irá encerrar o relacionamento com a companhia.\n",
        "df.drop(columns='customerID', inplace=True)\n",
        "\n",
        "# Remove a string '(automático)' dos nomes dos métodos de pagamento, pois ela é inútil.\n",
        "df['PaymentMethod'] = df['PaymentMethod'].str.replace(' (automatic)', '', regex=False)"
      ],
      "metadata": {
        "id": "7tHk3AqRBmSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3) Execute a célula abaixo para realizar a engenharia de atributos da base de dados.\n",
        "\n",
        "A engenharia de atributos é o processo de transformar os atributos em um formato adequado para o modelo de aprendizado de máquina. Neste exercício, precisamos transformar variáveis numéricas e categóricas.\n",
        "\n",
        "A maioria dos algoritmos de aprendizado de máquina requer valores numéricos. Portanto, todos os atributos categóricos disponíveis no conjunto de dados devem ser codificados em rótulos numéricos antes de treinarmos um modelo.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para realizar a engenharia de atributos.\n",
        "+ Perceba que a engenharia de atributos fez com que a matriz de atributos passe a ter 40 atributos.\n",
        "+ Note que os valores categóricos da coluna `Churn`, `No` e `Yes` serão mapeados nos valores 0 e 1, respectivamente. Portanto, como queremos predizer se ocorrerá o término do relaciomento com a empresa, i.e., `Churn`, a classe positiva é dada pelo valor `Yes` , que é mapeado no valor 1. Consequentemente, a classe negativa é dada pelo valor `No`, mapeado no valor 0."
      ],
      "metadata": {
        "id": "wJnPaeHcBxza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria uma cópia do DataFrame.\n",
        "df_transformed = df.copy()\n",
        "\n",
        "# Primeiro, realizamos a codificação de rótulo, a qual é usada para substituir valores categóricos por valores numéricos.\n",
        "# Essa codificação substitui cada valor categórico por um valor numérico binário (0 ou 1).\n",
        "\n",
        "# Lista de colunas com valores categóricos com apenas dois valores.\n",
        "label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService', 'Churn']\n",
        "\n",
        "# Executa a codificação de rótulo de colunas com apenas dois valores.\n",
        "# O que é feito é mapear os valores categóricos em valores numéricos, 0 ou 1.\n",
        "for column in label_encoding_columns:\n",
        "    if column == 'gender':\n",
        "        df_transformed[column] = df_transformed[column].map({'Female': 1, 'Male': 0})\n",
        "    else:\n",
        "        df_transformed[column] = df_transformed[column].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Na sequência, codificamos as colunas categóricas que possuem mais de dois possíveis valores usando a codificação one-hot.\n",
        "# A codificação one-hot cria uma nova coluna binária para cada valor da variável categórica.\n",
        "# A nova coluna contém zeros e uns indicando a ausência ou presença do valor sendo codificado.\n",
        "\n",
        "# Lista de colunas categóricas com mais de dois possíveis valores.\n",
        "one_hot_encoding_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n",
        "\n",
        "# Executa a codificação one-hot de colunas com mais de dois valores.\n",
        "df_transformed = pd.get_dummies(df_transformed, columns=one_hot_encoding_columns)\n",
        "\n",
        "print('Dimensão da base de dados após a engenharia de atributos:', df_transformed.shape)"
      ],
      "metadata": {
        "id": "IJQlzrqkB2Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4) Execute a célula abaixo para realizar o pré-processamento dos dados.\n",
        "\n",
        "Precisamos escalonar as colunas numéricas. Isso evitará que as colunas com valores grandes dominem o processo de aprendizado.\n",
        "\n",
        "Atributos com valores muito grandes tedem a dominar o processo de aprendizado. Entretanto, isso não significa que esses atributos sejam mais importantes na tarefa de predizer o valor desejado.\n",
        "\n",
        "A normalização de atributos deixa atributos com diferentes escalas com a mesma escala. Após a normalização, todas as variáveis têm influência semelhante no modelo, melhorando a estabilidade e o desempenho do algoritmo de aprendizado.\n",
        "\n",
        "Na célula de código abaixo, aplicamos a normalização min-max apenas aos atributos numéricos não binários, ou seja, atributos que possuem valores reais.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para realizar o pré-processamento dos dados."
      ],
      "metadata": {
        "id": "MGK-5Vi2CAuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de colunas com valores numéricos não binários, ou seja, colunas que possuem valores reais.\n",
        "min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "# Escalona atributos numéricos usando a normalização min-max.\n",
        "for column in min_max_columns:\n",
        "    # Obtém o valor mínimo da coluna (i.e., atributo).\n",
        "    min_column = df_transformed[column].min()\n",
        "    # Obtém o valor máximo da coluna (i.e., atributo).\n",
        "    max_column = df_transformed[column].max()\n",
        "    # Aplica a normalização min-max.\n",
        "    df_transformed[column] = (df_transformed[column] - min_column) / (max_column - min_column)"
      ],
      "metadata": {
        "id": "jDHOuKGoCECl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5) Execute a célula de código abaixo para criar a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ A primeira linha de comando remove da matriz de atributos a coluna `Churn`, pois ela será nosso rótulo.\n",
        "+ A segunda linha cria o vetor de rótulos contendo apenas a coluna `Churn`.\n",
        "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
      ],
      "metadata": {
        "id": "z9rvoVGOCIQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando o conjunto de pares de treinamento, X e y.\n",
        "X = df_transformed.drop(columns='Churn')\n",
        "y = df_transformed['Churn']\n",
        "\n",
        "# Atributos.\n",
        "print('Dimensão da matriz de atributos:', X.shape)\n",
        "# Rótulos.\n",
        "print('Dimensão do vetor de rótulos:', y.shape)"
      ],
      "metadata": {
        "id": "Ta0XPPPkCQjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6 ) Analise a proporção das classes.\n",
        "\n",
        "Execute a célula abaixo para visualizar a distribuição da variável target `Churn` usando um gráfico de barras.\n",
        "\n",
        "**DICAS**\n",
        "+ O valor de `Churn` igual a 1 (Sim), significa que o cliente cancelou o serviço.\n",
        "+ O valor de `Churn` igual a 0 (Não), significa que o cliente permaneceu com o serviço."
      ],
      "metadata": {
        "id": "gp8HK5pFV-yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar distribuição\n",
        "sns.countplot(x='Churn', data=df_transformed)\n",
        "plt.title('Distribuição de Churn (0=Não, 1=Sim)')\n",
        "plt.show()\n",
        "\n",
        "print(\"Contagem de Churn:\\n\", y.value_counts())\n",
        "print(\"\\nProporção de Churn:\\n\", y.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "te1ZTiUmV_Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.7 ) Após analisar o gráfico acima, interprete a distribuição das classes e responda:\n",
        "\n",
        "+ Este é um problema com classes balanceadas ou desbalanceadas?\n",
        "\n",
        "+ Baseado na sua resposta anterior, a acurácia é uma boa metrica a ser usada para mensurar a qualidade de um classificador?\n",
        "\n",
        "+ Caso a acurácia não seja uma boa métrica, qual ou quais outras métricas poderiam ser utilizadas?\n",
        "\n",
        "+ Quais possíveis impactos o desbalanceamento de classes pode ter na performance de modelos de classificação?\n",
        "\n",
        "+ Quantos clientes permaneceram na empresa e quantos cancelaram o serviço? Qual a porcentagem de clientes que cancelaram em relação ao total?\n",
        "\n",
        "**Justifique suas respostas.**\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ O desbalanceamento de classes ocorre quando uma classe possui significativamente mais exemplos que outra em um conjunto de dados.\n",
        "+ Esse desequilíbrio representa um sério desafio para algoritmos de aprendizado de máquina, pois os modelos tendem a se tornar enviesados em favor da classe majoritária. Como resultado, mesmo alcançando alta acurácia geral, o modelo frequentemente falha em identificar corretamente os casos da classe minoritária, que são justamente os mais críticos em muitos cenários práticos, como na detecção de fraudes ou na previsão de cancelamento de serviços.\n",
        "+ Para responder as questões 2 e 3, reveja a parte V do material sobre classificação."
      ],
      "metadata": {
        "id": "0VvApupuYLVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>"
      ],
      "metadata": {
        "id": "jkX-llJRatBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.8) Divida o conjunto total de amostras em conjuntos de treinamento e teste. O conjunto de treinamento deve conter 75% do total de amostras e o conjunto de teste os 25% restantes.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Use a função `train_test_split` e a configure com os seguintes parâmetros `test_size=0.25` e `random_state=seed`.\n",
        "+ Como o dataset é desbalanceado, use o parâmetro `stratify` configurado como `stratify=y` para criar conjuntos de treinamento de teste seguindo as porcentagens originais das duas classes do dataset.\n",
        "+ Sempre que possível, use a semente, `seed`, definida no item 1, para configurar o parâmetro `random_state` das funções e classes da biblioteca SciKit-Learn."
      ],
      "metadata": {
        "id": "dKLymSbKCXk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "SXJA2-_SCYn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.9 ) Treine um regressor logístico com o conjunto de treinamento e imprima sua acurácia nos conjuntos de treinamento e teste. A variável que irá armazenar o objeto da classe `LogisticRegression` deve se chamar `model1`.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Configure o parâmetro `penalty` da classe `LogisticRegression` com o valor `None`, ou seja, não vamos usar regularização.\n",
        "```python\n",
        "penalty=None\n",
        "```\n",
        "+ Configure o parâmetro `random_state` da classe `LogisticRegression` com a semente definida no item 1, ou seja,\n",
        "```python\n",
        "random_state=seed\n",
        "```"
      ],
      "metadata": {
        "id": "MNqi9QE3Cd25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "Ob0fb96VCusH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.10 ) Usando o modelo treinado no item anterior, plote a matriz de confusão para o **conjunto de teste**."
      ],
      "metadata": {
        "id": "PppF0zGsC0bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "XANcDmufC7Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.11 ) Use a função `classification_report` da biblioteca SciKit-Learn para plotar as métricas deste classificador para o **conjunto de teste**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para resolver este item, se baseie no código do seguinte exemplo: [classification_metrics.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classifica%C3%A7%C3%A3o/classification_metrics.ipynb)."
      ],
      "metadata": {
        "id": "TK6dFZCzDJba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "hQrEcRr9DSrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.12 ) Treine um perceptron com o conjunto de treinamento e imprima sua acurácia nos conjuntos de treinamento e teste. A variável que irá armazenar o objeto da classe `Perceptron` deve se chamar `model2`.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Configure o parâmetro `penalty` da classe `Perceptron` com o valor `None`, ou seja, não vamos usar regularização.\n",
        "```python\n",
        "penalty=None\n",
        "```\n",
        "+ Configure o parâmetro `random_state` da classe `Perceptron` com a semente definida no item 1, ou seja,\n",
        "```python\n",
        "random_state=seed\n",
        "```"
      ],
      "metadata": {
        "id": "Ik_Bu3B0F2Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "s7-O_IxFGOEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.13 ) Usando o modelo treinado no item anterior, plote a matriz de confusão para o **conjunto de teste**."
      ],
      "metadata": {
        "id": "rOPjGI0PHmIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "WdzAAFv4HrP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.14 ) Use a função `classification_report` da biblioteca SciKit-Learn para plotar as métricas deste classificador para o **conjunto de teste**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para resolver este item, se baseie no código do seguinte exemplo: [classification_metrics.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classifica%C3%A7%C3%A3o/classification_metrics.ipynb)."
      ],
      "metadata": {
        "id": "4zZhSLxeH3UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "zZo4HW33IK8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.15 ) Após analisar as métricas e matrizes de confusão dos modelos, responda:\n",
        "\n",
        "+ Baseando-se nas métricas mais indicadas ao problema deste exercício, qual é o melhor modelo?\n",
        "+ Após analisar as taxas de falsos positivos e falsos negativos do melhor modelo, poderíamos confiar neste modelo para fazer predições do `Churn`?\n",
        "\n",
        "**Justifique todas as respostas**\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Para responder a segunda questão, calcule as taxas de falsos positivos e falsos negativos a partir da matriz de confusão do melhor modelo. Lembre-se que a classe positiva é a `Churn` e a negativa a `No Churn`. Um bom classificador para a tarefa de predição do `Churn` deve ter ambos os valores o mais próximos de zero o possível."
      ],
      "metadata": {
        "id": "-2txpGdjJWWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>"
      ],
      "metadata": {
        "id": "6kD5wjjSKfbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.16 ) Execute a célula de código abaixo para executar um código que avalia a importância dos atributos da base de dados usando a técnica conhecida como `Permutation feature importance`.\n",
        "\n",
        "`Permutation feature importance` é uma técnica de inspeção de modelos que mede a contribuição de cada atributo para o desempenho de um modelo. Essa técnica envolve embaralhar aleatoriamente os valores de um único atributo e observar a degradação resultante no desempenho do modelo. Ao quebrar a relação entre o atributo e o rótulo, determinamos o quanto o modelo depende desse atributo específico.\n",
        "\n",
        "Por meio da `Permutation feature importance`, nós conseguimos verificar quais atributos mais influenciam a predição de ***Churn***."
      ],
      "metadata": {
        "id": "qzE-ok4iLK0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite abaixo o nome do melhor modelo: model1 ou model2.\n",
        "best_model ="
      ],
      "metadata": {
        "id": "pkEH6s9oNg0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a importância por permutação no conjunto de TESTE\n",
        "result = permutation_importance(\n",
        "    best_model, X_test, y_test, n_repeats=20, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Organizar as importâncias em ordem DECRESCENTE (da maior para a menor)\n",
        "sorted_idx = result.importances_mean.argsort()[::-1]\n",
        "\n",
        "# Mostrar apenas as 10 features mais importantes\n",
        "top_n = 10\n",
        "sorted_idx_top = sorted_idx[:top_n]\n",
        "feature_names_top = [X_test.columns.tolist()[i] for i in sorted_idx_top]\n",
        "\n",
        "plt.figure()  # Aumentei um pouco a altura para 10 features\n",
        "bars = plt.barh(feature_names_top, result.importances_mean[sorted_idx_top])\n",
        "\n",
        "# Inverter o eixo Y para mostrar a feature mais importante no topo\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.xlabel(\"Diminuição Média na Acurácia\")\n",
        "plt.title(f\"Top {top_n} - Importância dos Atributos por Permutação (Conjunto de Teste)\")\n",
        "\n",
        "# Adicionar os valores nas barras\n",
        "for i, v in enumerate(result.importances_mean[sorted_idx_top]):\n",
        "    plt.text(v, i, f\" {v:.4f}\", va='center')\n",
        "\n",
        "# Ajustar automaticamente o limite do eixo X se necessário\n",
        "max_importance = result.importances_mean[sorted_idx_top].max()\n",
        "plt.xlim(right=max_importance * 1.15)  # 15% de margem\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DsbtDpo6XN-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.17 ) Após analisar o resultado do item anterior, responda:\n",
        "\n",
        "* Quais os três atributos aparecem como os mais importantes no gráfico de Permutation Importance para o conjunto de teste?\n",
        "* Você consegue imaginar o motivo do primeiro atributo que aparece no gráfico anterior ter uma importância bem maior do que a dos outros atributos?\n",
        "  - Para responder estar pergunta, volte ao item 1 e compare os valores da coluna referente a este atributo com os valores da coluna `Churn` (a coluna de rótulos). A chance de churn aumenta ou diminui com o aumento do valor dos elementos deste atributo?"
      ],
      "metadata": {
        "id": "7yNWizexKJO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>"
      ],
      "metadata": {
        "id": "M7dkSGfZKJSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.18 ) Execute a célula de código abaixo. O código analisa a relação entre o tempo de relacionamento (tenure) e a taxa de churn, calculando para cada mês de tenure a proporção de clientes que cancelaram o serviço e plotando esses dados em um gráfico de linha com uma curva de tendência, permitindo visualizar como a probabilidade de churn evolui ao longo do tempo de contrato do cliente."
      ],
      "metadata": {
        "id": "Z-xDaDcguYMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar uma cópia do DataFrame original para preservar os dados não transformados\n",
        "df_plot = df.copy()\n",
        "\n",
        "# Agrupar os dados por tenure e calcular a taxa média de churn\n",
        "churn_by_tenure = df_plot.groupby('tenure')['Churn'].apply(\n",
        "    lambda x: (x == 'Yes').mean()  # Calcular proporção de churn\n",
        ").reset_index()\n",
        "\n",
        "# Plotar a curva de taxa de churn vs. tenure\n",
        "plt.figure()\n",
        "plt.plot(churn_by_tenure['tenure'], churn_by_tenure['Churn'], marker='o', linestyle='-', linewidth=2)\n",
        "plt.xlabel('Tempo de Relacionamento (Tenure em Meses)')\n",
        "plt.ylabel('Taxa de Churn')\n",
        "plt.title('Relação entre Tenure e Taxa de Churn')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adicionar uma linha de tendência para facilitar a interpretação\n",
        "z = np.polyfit(churn_by_tenure['tenure'], churn_by_tenure['Churn'], 3)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(churn_by_tenure['tenure'], p(churn_by_tenure['tenure']), \"r--\", alpha=0.8, label='Tendência')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "81UuFMEiuYry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.19 ) Analisando a relação entre tempo de relacionamento (tenure) e taxa de churn mostrada no gráfico anterior, descreva qual é o padrão observado e que implicações práticas essa tendência teria para a estratégia de retenção de clientes da empresa?"
      ],
      "metadata": {
        "id": "iGUCsUGrwcbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>"
      ],
      "metadata": {
        "id": "JH-pAlSU6CYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) **Exercício sobre o balanceamento de bases de dados**\n",
        "\n",
        "Neste exercício usaremos novamente a base de dados para predição de `Churn` usada no exercício anterior. Porém, desta vez, aplicaremos uma técnica de reamostragem de dados que deixará o dataset mais balanceado e menos enviesado em direção à classe majoritária.\n",
        "\n",
        "Para balancear a base de dados, usaremos a biblioteca **imbalanced-learn (imblearn)**. Ela é uma biblioteca Python especializada no tratamento de conjuntos de dados desbalanceados. Ela oferece diversas técnicas de reamostragem para equilibrar a distribuição entre classes, como:\n",
        "\n",
        "- **Oversampling**: Aumenta a classe minoritária (por exemplo, SMOTE, que cria amostras sintéticas).\n",
        "- **Undersampling**: Reduz a classe majoritária.\n",
        "- **Métodos combinados**: Abordagens híbridas.\n",
        "\n",
        "Essa biblioteca é crucial porque conjuntos desbalanceados prejudicam a performance de algoritmos de aprendizado de máquina, que tendem a ignorar a classe minoritária.\n",
        "\n",
        "Nós usaremos a classe SMOTE (Synthetic Minority Over-sampling Technique) da biblioteca imblearn. Ela é uma técnica avançada de oversampling que cria exemplos sintéticos da classe minoritária em vez de simplesmente duplicar instâncias existentes.\n",
        "\n",
        "**Funcionamento**:\n",
        "\n",
        "1. Seleciona exemplos da classe minoritária\n",
        "\n",
        "2. Encontra seus k-vizinhos mais próximos\n",
        "\n",
        "3. Gera novas amostras através de interpolação entre esses pontos\n",
        "\n",
        "**Vantagens**:\n",
        "\n",
        "- Evita overfitting causado por duplicação simples\n",
        "\n",
        "- Expande o espaço de atributos da classe minoritária\n",
        "\n",
        "- Melhora a capacidade do modelo de generalizar\n",
        "\n",
        "É uma das técnicas mais populares no imblearn para lidar com desbalanceamento de classes.\n",
        "\n",
        "**Referência**\n",
        "\n",
        "[1] https://imbalanced-learn.org/stable/\n"
      ],
      "metadata": {
        "id": "-RLaGtFx2wZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 ) Execute a célula de código abaixo. Ela realiza o pré-processamento, engenharia de atributos (ou features) e análise exploratória da base de dados de churn. As principais etapas são:\n",
        "\n",
        "1. **Pré-processamento dos dados:**\n",
        "   - Converte colunas para tipos adequados\n",
        "   - Remove valores nulos e colunas irrelevantes\n",
        "   - Limpa strings em métodos de pagamento\n",
        "\n",
        "2. **Engenharia de features:**\n",
        "   - Aplica **label encoding** em variáveis categóricas binárias\n",
        "   - Usa **one-hot encoding** em variáveis com múltiplas categorias\n",
        "   - Normaliza features numéricas com **min-max scaling**\n",
        "\n",
        "3. **Análise exploratória:**\n",
        "   - Separa os dados em features (X) e target (y)\n",
        "   - Visualiza a distribuição da variável target \"Churn\"\n",
        "   - Mostra estatísticas do desbalanceamento entre classes\n",
        "\n",
        "A gráfico plotado ao final revela que as classes estão desbalanceadas (aproximadamente 73% Não-Churn vs 27% Churn)."
      ],
      "metadata": {
        "id": "MH0Uo6BPcbVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importe todas os módulos necessários.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE, SMOTEN, ADASYN, KMeansSMOTE, BorderlineSMOTE\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import urllib\n",
        "\n",
        "# Reseta o gerador de sequências pseudo aleatórias.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Baixa as bases de dados do dropbox.\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/xg2hzt0p8p3zsjd/telco_customer_churn.csv?dl=1', 'telco_customer_churn.csv')\n",
        "\n",
        "# Importa os arquivos CSV.\n",
        "df = pd.read_csv('./telco_customer_churn.csv')\n",
        "\n",
        "# Força a coluna 'TotalCharges' a ser do tipo numérico.\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Remove exemplos (i.e., linhas) com valores nulos.\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove a coluna 'customerID' pois ela é inútil para explicar se o cliente não irá encerrar o relacionamento com a companhia.\n",
        "df.drop(columns='customerID', inplace=True)\n",
        "\n",
        "# Remove a string '(automático)' dos nomes dos métodos de pagamento, pois ela é inútil.\n",
        "df['PaymentMethod'] = df['PaymentMethod'].str.replace(' (automatic)', '', regex=False)\n",
        "\n",
        "# Cria uma cópia do DataFrame.\n",
        "df_transformed = df.copy()\n",
        "\n",
        "# Primeiro, realizamos a codificação de rótulo, a qual é usada para substituir valores categóricos por valores numéricos.\n",
        "# Essa codificação substitui cada valor categórico por um valor numérico binário (0 ou 1).\n",
        "\n",
        "# Lista de colunas com valores categóricos com apenas dois valores.\n",
        "label_encoding_columns = ['gender', 'Partner', 'Dependents', 'PaperlessBilling', 'PhoneService', 'Churn']\n",
        "\n",
        "# Executa a codificação de rótulo de colunas com apenas dois valores.\n",
        "# O que é feito é mapear os valores categóricos em valores numéricos, 0 ou 1.\n",
        "for column in label_encoding_columns:\n",
        "    if column == 'gender':\n",
        "        df_transformed[column] = df_transformed[column].map({'Female': 1, 'Male': 0})\n",
        "    else:\n",
        "        df_transformed[column] = df_transformed[column].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Na sequência, codificamos as colunas categóricas que possuem mais de dois possíveis valores usando a codificação one-hot.\n",
        "# A codificação one-hot cria uma nova coluna binária para cada valor da variável categórica.\n",
        "# A nova coluna contém zeros e uns indicando a ausência ou presença do valor sendo codificado.\n",
        "\n",
        "# Lista de colunas categóricas com mais de dois possíveis valores.\n",
        "one_hot_encoding_columns = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
        "                            'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n",
        "\n",
        "# Executa a codificação one-hot de colunas com mais de dois valores.\n",
        "df_transformed = pd.get_dummies(df_transformed, columns=one_hot_encoding_columns)\n",
        "\n",
        "print('Dimensão da base de dados após a engenharia de atributos:', df_transformed.shape)\n",
        "\n",
        "# Lista de colunas com valores numéricos não binários, ou seja, colunas que possuem valores reais.\n",
        "min_max_columns = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "# Escalona atributos numéricos usando a normalização min-max.\n",
        "for column in min_max_columns:\n",
        "    # Obtém o valor mínimo da coluna (i.e., atributo).\n",
        "    min_column = df_transformed[column].min()\n",
        "    # Obtém o valor máximo da coluna (i.e., atributo).\n",
        "    max_column = df_transformed[column].max()\n",
        "    # Aplica a normalização min-max.\n",
        "    df_transformed[column] = (df_transformed[column] - min_column) / (max_column - min_column)\n",
        "\n",
        "# Criando o conjunto de pares de treinamento, X e y.\n",
        "X = df_transformed.drop(columns='Churn')\n",
        "y = df_transformed['Churn']\n",
        "\n",
        "# Plotar distribuição\n",
        "sns.countplot(x='Churn', data=df_transformed)\n",
        "plt.title('Distribuição de Churn (0=Não, 1=Sim)')\n",
        "plt.show()\n",
        "\n",
        "print(\"Contagem de Churn:\\n\", y.value_counts())\n",
        "print(\"\\nProporção de Churn:\\n\", y.value_counts(normalize=True))\n",
        "\n",
        "# Divide a base de dados de forma estratificada em conjuntos de treinamento e teste.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=seed)\n",
        "\n",
        "# Atributos.\n",
        "print('\\n\\nDimensão da matriz de atributos de treinamento:', X_train.shape)\n",
        "print('Dimensão da matriz de atributos de teste:', X_test.shape)\n",
        "# Rótulos.\n",
        "print('Dimensão do vetor de rótulos de treinamento:', y_train.shape)\n",
        "print('Dimensão do vetor de rótulos de teste:', y_test.shape)"
      ],
      "metadata": {
        "id": "5Sj7R2IcVje9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 ) Treine um regressor logístico com o conjunto de treinamento. A variável que irá armazenar o objeto da classe `LogisticRegression` deve se chamar `model1`.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Configure o parâmetro `penalty` da classe `LogisticRegression` com o valor `None`, ou seja, não vamos usar regularização.\n",
        "```python\n",
        "penalty=None\n",
        "```\n",
        "+ Configure o parâmetro `random_state` da classe `LogisticRegression` com a semente definida no item 1, ou seja,\n",
        "```python\n",
        "random_state=seed\n",
        "```"
      ],
      "metadata": {
        "id": "HCCAFNDkrFc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite o código do item aqui."
      ],
      "metadata": {
        "id": "2XyEIGFArOGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 ) Use a função `classification_report` da biblioteca SciKit-Learn para plotar as métricas deste classificador para o **conjunto de teste**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Não se esqueça que você deve usar o `model1`.\n",
        "+ Para resolver este item, se baseie no código do seguinte exemplo: [classification_with_cross_validation.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classificação/classification_with_cross_validation.ipynb)."
      ],
      "metadata": {
        "id": "YAOLnXf7LrXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite o código do item aqui."
      ],
      "metadata": {
        "id": "wzybcW-hLrpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4 ) Compare as métricas da classe majoritária (0) com as da minoritária (1). Qual a diferença mais significativa e o que isso revela sobre o viés do modelo? (**Justifique sua resposta**)."
      ],
      "metadata": {
        "id": "W5vrEERgMWyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n",
        "\n"
      ],
      "metadata": {
        "id": "GRUTyPo8MYAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.5 ) Execute a célula de código abaixo. O código abaixo aplica a técnica SMOTE para balancear o conjunto de treinamento, criando amostras sintéticas da classe minoritária, e em seguida gera um gráfico de barras comparativo que mostra a distribuição das classes antes e depois do balanceamento.\n",
        "\n"
      ],
      "metadata": {
        "id": "N0uNCtM9-YVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar SMOTE apenas no conjunto de treinamento.\n",
        "smote = SMOTE(random_state=seed)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Comparação lado a lado das distribuições das classes antes e após a aplicação do SMOTE.\n",
        "plt.figure()\n",
        "\n",
        "original_counts = y_train.value_counts()\n",
        "resampled_counts = pd.Series(y_train_resampled).value_counts()\n",
        "\n",
        "categorias = ['Classe 0\\n(Não Churn)', 'Classe 1\\n(Churn)']\n",
        "antes = [original_counts[0], original_counts[1]]\n",
        "depois = [resampled_counts[0], resampled_counts[1]]\n",
        "\n",
        "x_pos = np.arange(len(categorias))\n",
        "largura = 0.35\n",
        "\n",
        "plt.bar(x_pos - largura/2, antes, largura, label='ANTES do SMOTE',\n",
        "        color='lightblue', edgecolor='navy', alpha=0.8)\n",
        "plt.bar(x_pos + largura/2, depois, largura, label='APÓS o SMOTE',\n",
        "        color='lightcoral', edgecolor='darkred', alpha=0.8)\n",
        "\n",
        "plt.title('Distribuição de Classes\\nAntes e Depois do SMOTE',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Número de Amostras', fontsize=12)\n",
        "plt.xticks(x_pos, categorias)\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for i, v in enumerate(antes):\n",
        "    plt.text(i - largura/2, v + max(antes + depois)*0.01, str(v),\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "for i, v in enumerate(depois):\n",
        "    plt.text(i + largura/2, v + max(antes + depois)*0.01, str(v),\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a5pyQE3K_wu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.6 ) Treine um novo regressor logístico com o conjunto de treinamento. A variável que irá armazenar o objeto da classe `LogisticRegression` deve se chamar `model2`.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Configure o parâmetro `penalty` da classe `LogisticRegression` com o valor `None`, ou seja, não vamos usar regularização.\n",
        "```python\n",
        "penalty=None\n",
        "```\n",
        "+ Configure o parâmetro `random_state` da classe `LogisticRegression` com a semente definida no item 1, ou seja,\n",
        "```python\n",
        "random_state=seed\n",
        "```"
      ],
      "metadata": {
        "id": "HIeg0KrYCDnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "L7pkf8XZN5qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.7 ) Use a função `classification_report` da biblioteca SciKit-Learn para plotar as métricas deste novo classificador para o **conjunto de teste**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Não se esqueça que você deve usar o `model2`.\n",
        "+ Para resolver este item, se baseie no código do seguinte exemplo: [classification_with_cross_validation.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classificação/classification_with_cross_validation.ipynb)."
      ],
      "metadata": {
        "id": "POzg2w2JN_BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite aqui o código do exercício."
      ],
      "metadata": {
        "id": "-zPFKyqXN_OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.8 ) Dado que o custo de não predizer a perda um cliente (i.e., `Churn`) é bastante alto, pois envolve a perda do cliente mais o custo de aquisição de um novo cliente, responda:\n",
        "\n",
        "* Qual métrica é a mais adequada para se medir o desempenho do classificador?\n",
        "* Se o objetivo é maximizar a detecção (i.e., predição) de clientes em risco de churn (classe 1), os resultados pós-SMOTE são melhores?\n",
        "* Verifique que acurácia geral diminuiu após o uso do SMOTE. Por que isso aconteceu e por que a acurácia pode ser enganosa para avaliar modelos em bases desbalanceadas?\n",
        "\n",
        "\n",
        "(**Justifique todas as respostas**)\n",
        "\n",
        "**DICAS**\n",
        "+ Para te ajudar a responder as perguntas, revise a parte V de classificação.\n",
        "+ Lembre-se que o `Churn` é a classe positiva e que predições incorretas de exemplos desta classe são considerados falsos negativos. Assim, classificar um exemplo que realmente indica a perda um cliente (i.e., `Churn`) como `no-Churn` (i.e., classe negativa) é um falso positivo.\n",
        "+ Em geral, o custo de aquisição de um novo cliente é de 5 a 7 vezes maior que a retenção. Isso significa que mesmo que o classificador prediga incorretamente que um cliente irá encerrar seu contrato ou assinatura, oferecer um desconto ou benefício para este cliente tem um valor muito baixo em relação ao `Churn` e à aquisição de um novo cliente. Além disso, descontos ou benefícios ajudam a fidelizar o cliente."
      ],
      "metadata": {
        "id": "Pdjju_5VCDql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n",
        "\n"
      ],
      "metadata": {
        "id": "LlPRPZz3oGuN"
      }
    }
  ]
}