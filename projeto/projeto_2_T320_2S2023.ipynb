{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3319440",
      "metadata": {
        "id": "e3319440"
      },
      "source": [
        "# Projeto 2 - T320 (2S2023)\n",
        "\n",
        "\n",
        "### Instruções\n",
        "\n",
        "1. Antes de começar, você deve clicar na opção \"Copiar para o Drive\" na barra superior do Colab. Depois de clicar nela, verifique se você está trabalhando nessa versão do notebook para que seu trabalho seja salvo.\n",
        "2. Quando você terminar os exercícios do projeto, vá até o menu do Jupyter ou Colab e selecione a opção para fazer download do notebook.\n",
        "    * Os notebooks tem extensão .ipynb.\n",
        "    * Este deve ser o arquivo que você irá entregar.\n",
        "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
        "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
        "3. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção de anexar arquivos à tarefa.\n",
        "4. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão aceitas.\n",
        "5. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
        "6. Todas as questões têm o mesmo peso.\n",
        "7. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Substitua os nomes que já estão no campo abaixo.\n",
        "8. Você pode consultar todo o material de aula.\n",
        "9. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
        "10. Boa sorte!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2293a7f1",
      "metadata": {
        "id": "2293a7f1"
      },
      "source": [
        "**Nomes e matrículas**:\n",
        "\n",
        "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
        "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
        "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a420f2",
      "metadata": {
        "id": "88a420f2"
      },
      "source": [
        "### 1) Neste exercício, você irá utilizar validação cruzada para encontrar a melhor configuração para que uma rede MLP separe quatro classes.\n",
        "\n",
        "1. Execute a célula abaixo e analise a figura gerada. A figura mostra os exemplos de quatro classes.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Perceba que ao final da célula abaixo, o conjunto total de exemplos já é divido em conjuntos de treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6845091a",
      "metadata": {
        "id": "6845091a"
      },
      "outputs": [],
      "source": [
        "# Importe todas os módulos necessários.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import seaborn as sns\n",
        "import urllib\n",
        "\n",
        "# Reseta o gerador de sequências pseudo aleatórias.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Baixa as bases de dados do dropbox.\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/t3pdze8a0qgzyxy/fourMoons.csv?dl=1', 'fourMoons.csv')\n",
        "\n",
        "# Importa os arquivos CSV.\n",
        "df = pd.read_csv('./fourMoons.csv', header=None)\n",
        "\n",
        "# Obtendo a matriz de atributos e o vetor de rótulos.\n",
        "X = df[[0, 1]].to_numpy()\n",
        "y = df[2].to_numpy()\n",
        "\n",
        "# Plot the classes.\n",
        "idx0 = np.argwhere(y==0)\n",
        "idx1 = np.argwhere(y==1)\n",
        "idx2 = np.argwhere(y==2)\n",
        "idx3 = np.argwhere(y==3)\n",
        "plt.plot(X[idx0,0], X[idx0,1], '.', label='Class 0')\n",
        "plt.plot(X[idx1,0], X[idx1,1], 'rx', label='Class 1')\n",
        "plt.plot(X[idx2,0], X[idx2,1], 'ko', label='Class 2')\n",
        "plt.plot(X[idx3,0], X[idx3,1], 'c*', label='Class 3')\n",
        "plt.xlabel('$x_1$', fontsize=14)\n",
        "plt.ylabel('$x_2$', fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Imprime as dimensões do conjunto total de amostras.\n",
        "print('Dimensão da matriz de atributos, X:', X.shape)\n",
        "print('Dimensão do vetor de rótulos, y:', y.shape)\n",
        "\n",
        "# Split array into random train and test subsets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f05cd22",
      "metadata": {
        "id": "4f05cd22"
      },
      "source": [
        "2. Use busca exaustiva (`GridSearchCV`) e o **conjunto total de amostras** para treinar um objeto da classe `MLPClassifier` para encontrar os valores ideais para alguns parâmetros da rede MLP de tal forma que o modelo classifique o melhor possível as duas classes.\n",
        "\n",
        "O objeto da classe `GridSearchCV` automatiza o processo de busca pelo melhor conjunto de parâmetros de um modelo, neste caso, os parâmetros do objeto da classe `MLPClassifier`, mas poderia ser de qualquer outro modelo que necessite de ajuste fino de seus parâmetros. O dicionário de parâmetros, chamado no código de exemplo de `parameters`, que é passado para o `GridSearchCV` contém os parâmetros do objeto da classe `MLPClassifier` que desejamos testar e verificar qual combinação deles resulta no melhor resultado. Portanto, o `GridSearchCV` automatiza os testes que vão descobrir dentre esses valores do dicionário `parameters` quais são os melhores para cada parâmetro. Portanto, o que o `GridSearchCV` faz é configurar o objeto da classe `MLPClassifier` com todas as combinações possíveis dos parâmetros passados no dicionário `parameters` e retornar, ao final, a melhor combinação destes parâmetros.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Ao instanciar o objeto da classe `MLPClassifier` configure o parâmetro de entrada `max_iter` com o valor `10000`.\n",
        "+ Use **grid search** (ou seja, um objeto da classe `GridSearchCV`) para encontrar: (i) o número ideal de nós e camadas escondidas, (ii) a função de ativação ideal dos nós, (iii) o melhor otimizador e (iv) o valor da semente do gerador de sequências pseudo-aleatórias.\n",
        "+ O `GridSearchCV` deve testar o  seguinte conjunto de parâmetros e valores:\n",
        "    * `'hidden_layer_sizes'` com os valores `(4,)`, `(6,)`, `(4,2)`, e `(6,3)`.\n",
        "    * `'activation'` com os valores `'logistic'`, `'tanh'`, e `'relu'`.\n",
        "    * `'random_state'`  com os valores `1`, `42`, `51`, `69`, e `250`.\n",
        "+ O treinamento pode ser demorado, então pegue um café e tenha paciência.\n",
        "+ Ao instanciar o objeto da classe `GridSearchCV`, configure-o com os seguintes parâmetros:\n",
        "    * número de *folds* para o k-Fold igual a 5, ou seja, `cv=5`.\n",
        "    * acurácia como sendo a estratégia para avaliar o desempenho do modelo, ou seja, `scoring='accuracy'`.\n",
        "    * usar todos os processadores disponíveis para acelerar a validação cruzada do modelo, ou seja, `n_jobs=-1`.\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbcf9df6",
      "metadata": {
        "id": "dbcf9df6"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838cba69",
      "metadata": {
        "id": "838cba69"
      },
      "source": [
        "3. Após o treinamento, imprima quais foram os melhores valores encontrados pelo grid search.\n",
        "\n",
        "**DICAS**:\n",
        "    \n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77eaa653",
      "metadata": {
        "id": "77eaa653"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dcc0f45",
      "metadata": {
        "id": "0dcc0f45"
      },
      "source": [
        "4. Usando o modelo com os melhores hiperparâmetros, calcule e imprima as acurácias com os conjuntos de treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d30e2a5",
      "metadata": {
        "id": "3d30e2a5"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee93792",
      "metadata": {
        "id": "aee93792"
      },
      "source": [
        "5. Plote a matriz de confusão da rede MLP para o **conjunto total de amostras**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_metrics.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/perceptron/perceptron_xor_problem.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e6fc40",
      "metadata": {
        "id": "83e6fc40"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af4b27ca",
      "metadata": {
        "id": "af4b27ca"
      },
      "source": [
        "6. Use a função `classification_report` da biblioteca SciKit-Learn para imprimir as métricas de classificação para o **conjunto total de exemplos**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_with_cross_validation.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classificação/classification_with_cross_validation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac516893",
      "metadata": {
        "id": "ac516893"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df716af0",
      "metadata": {
        "id": "df716af0"
      },
      "source": [
        "7. Usando o modelo treinado com a melhor ordem para o polinômio de separação, plote as regiões de decisão deste classificador.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_with_cross_validation.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classificação/classification_with_cross_validation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b3e287",
      "metadata": {
        "id": "b0b3e287"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13954b4",
      "metadata": {
        "id": "b13954b4"
      },
      "source": [
        "8. Analise a matriz de confusão, as métricas impressas no item 5 e as regiões de decisão, o que podemos concluir sobre este classificador? (**Justifique sua resposta**)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8321c28",
      "metadata": {
        "id": "a8321c28"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef229953",
      "metadata": {
        "id": "ef229953"
      },
      "source": [
        "9. O que você nota de diferença entre este modelo (MLP) e o modelo que treinamos no exercício 1 do projeto 1 (regressor softmax)?\n",
        "\n",
        "**Justifique sua resposta**.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Com a MLP, precisamos encontrar um polinômio e sua respectiva ordem para obtermos uma separação perfeita das classes?\n",
        "+ Quando usamos polinômios, a não-linearidade é introduzida pelos atributos do polinômio, os quais fazem com que o mapeamente entre as entradas e a saída seja não-linear, criando as funções discriminantes com os formatos que precisamos para separar as classes. No caso da MLP, quem introduz a não linearidade necessária para obtermos a separação entre as classes? Para responder essa pergunta, lembre-se que as MLPs são compostas por combinações de nós que possuem funções de ativação não lineares, como as funções logística e tangente hiperbólica."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b03edd",
      "metadata": {
        "id": "e5b03edd"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ded03ee0",
      "metadata": {
        "id": "ded03ee0"
      },
      "source": [
        "### 2) Exercício sobre o modelo do neurônio de McCulloch e Pitts.\n",
        "\n",
        "Usando-se o modelo do neurônio de McCulloch e Pitts, qual seria o valor do **limiar de ativação**, $\\theta$, para classificar a função booleana dada pela tabela abaixo? Desenhe a função de ativação e o neurônio, indicando quais entradas são inibitórias, caso haja alguma.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Como este exercício é teórico, anexe o arquivo com sua resposta em formato **pdf** na tarefa do MS Teams.\n",
        "+ Você pode precisar ter uma ou mais entradas inibitórias para encontrar o valor de $\\theta$.\n",
        "    + Entradas inibitórias são entradas que têm seus valores **negados**.\n",
        "    + Para **negar** um valor de entrada, você pode, por exemplo, multiplicá-lo por $-1$.\n",
        "+ Os atributos de entrada são `x1`, `x2` e `x3` e o valor esperado, ou seja, a saída do neurônio, é dado por `y`.\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|:--:|:--:|:--:|:-:|\n",
        "|  0 |  0 |  0 | 0 |\n",
        "|  0 |  0 |  1 | 0 |\n",
        "|  0 |  1 |  0 | 0 |\n",
        "|  0 |  1 |  1 | 0 |\n",
        "|  1 |  0 |  0 | 0 |\n",
        "|  1 |  0 |  1 | 1 |\n",
        "|  1 |  1 |  0 | 0 |\n",
        "|  1 |  1 |  1 | 0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7353510",
      "metadata": {
        "id": "a7353510"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccd189dc",
      "metadata": {
        "id": "ccd189dc"
      },
      "source": [
        "### 3) Exercício sobre o uso da rede Multi Layer Perceptron (MLP) para regressão.\n",
        "\n",
        "Neste exercício, você assumirá o papel de analista de negócios de uma empresa do setor de Logística. Seu objetivo é prever o tempo estimado de chegada de uma remessa em número de dias. Você usará um conjunto de dados sintético chamado de *Shipping Logs Dataset*. Este conjunto de dados contém dados completos de remessas para todos os produtos entregues, incluindo tempo estimado, prioridade da remessa, transportadora e origem. Ele tem cerca de 10.000 linhas, 12 colunas de atributos.\n",
        "\n",
        "\n",
        "|    **Atributo**   |                                 **Descrição**                                 |\n",
        "|:--------------------:|:-------------------------------------------------------------------------------:|\n",
        "|    OnTimeDelivery    | Indicated whether the shipment was delivered on time - label for Classification |\n",
        "|  ActualShippingDays  |                  Number of days it took to deliver the shipment                 |\n",
        "|        Carrier       |                            Carrier used for shipment                            |\n",
        "|   YShippingDistance  |                        Distance of shipment on the Y-axis                       |\n",
        "|   XShippingDistance  |                        Distance of shipment on the X-axis                       |\n",
        "|      InBulkOrder     |                                Is it a bulk order                               |\n",
        "|    ShippingOrigin    |                                Origin of shipment                               |\n",
        "|       OrderDate      |                          Date when the order was placed                         |\n",
        "|        OrderID       |                                     Order ID                                    |\n",
        "|   ShippingPriority   |                               Priority of Shipping                              |\n",
        "|       ProductId      |                                    Product ID                                   |\n",
        "|     ComputerBrand    |                Indicates a computer brand that is getting shipped               |\n",
        "|     ComputerModel    |                Indicates a computer model that is getting shipped               |\n",
        "|      ScreenSize      |                              indicated screen size                              |\n",
        "|     PackageWeight    |                      Weight of the package getting shipped                      |\n",
        "|                      | **Rótulo** |\n",
        "| ExpectedShippingDays |                Expected days for shipment - label for Regression                |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. Execute a célula de código abaixo para importar os dados e as bibliotecas necessárias.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Após a execução bem sucedida da célula abaixo, você visualizará as 5 primeiras linhas da base de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50afa862",
      "metadata": {
        "id": "50afa862"
      },
      "outputs": [],
      "source": [
        "# Importe todas as bibliotecas necessárias.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "from math import sqrt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "import urllib\n",
        "\n",
        "# Reseta o gerador de sequências pseudo aleatórias.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Baixa as bases de dados do dropbox.\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/33dse6o1be8097r/ShippingLogs.csv?dl=1', 'ShippingLogs.csv')\n",
        "\n",
        "# Usando a biblioteca pandas para ler a base de dados.\n",
        "df = pd.read_csv('./ShippingLogs.csv')\n",
        "\n",
        "# Mostrando os primeiros cinco exemplos.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cafc130",
      "metadata": {
        "id": "6cafc130"
      },
      "source": [
        "2. Execute a célula de código abaixo para verificar a existência de valores nulos e duplicados e remover colunas inúteis.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para limpar a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989907f5",
      "metadata": {
        "id": "989907f5"
      },
      "outputs": [],
      "source": [
        "# Verificando a existência de valores duplicados.\n",
        "N_null = sum(df.isnull().sum())\n",
        "print(\"O dataset contém {} valores nulos\".format(N_null))\n",
        "\n",
        "# Removendo valores duplicados.\n",
        "N_dupli = sum(df.duplicated(keep='first'))\n",
        "dataset = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
        "print(\"O dataset contém {} valores duplicados\".format(N_dupli))\n",
        "\n",
        "# Removendo colunas que não trazem informação útil para o problema.\n",
        "df1 = df.drop([\"OrderID\", \"ProductId\", \"OnTimeDelivery\", \"ActualShippingDays\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3ebbeb7",
      "metadata": {
        "id": "f3ebbeb7"
      },
      "source": [
        "3. Execute a célula abaixo para realizar a engenharia de atributos da base de dados.\n",
        "\n",
        "A engenharia de atributos é o processo de transformar os atributos em um formato adequado para o modelo de aprendizado de máquina. Neste exercício, precisamos transformar variáveis categóricas.\n",
        "\n",
        "A maioria dos algoritmos de aprendizado de máquina requer valores numéricos. Portanto, todos os atributos categóricos (strings) disponíveis no conjunto de dados devem ser codificados em rótulos numéricos antes de treinarmos um modelo.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para realizar a engenharia de atributos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbd5bff",
      "metadata": {
        "id": "dfbd5bff"
      },
      "outputs": [],
      "source": [
        "# Converte colunas categóricas em colunas numéricas com valores começando de 1.\n",
        "encoder = ce.OrdinalEncoder(cols=['Carrier', 'InBulkOrder', 'ShippingOrigin', 'ShippingPriority'])\n",
        "df1 = encoder.fit_transform(df1)\n",
        "\n",
        "# Converte a coluna 'OrderDate' em uma data, com o dia em primeiro lugar.\n",
        "df1['Date'] = pd.to_datetime(df1['OrderDate'], dayfirst=False)\n",
        "\n",
        "# Cria colunas com o mês, ano, dia e semana da compra.\n",
        "df1['Month'] = df1['Date'].dt.month\n",
        "df1['Year'] = df1['Date'].dt.year\n",
        "df1['Day'] = df1['Date'].dt.day\n",
        "df1['Week'] = df1['Date'].dt.isocalendar().week\n",
        "\n",
        "# Cria a coluna 'Distance' com a distância até a entrega do produto.\n",
        "df1['Distance'] = pow(pow(df1['XShippingDistance'], 2) + pow(df1['YShippingDistance'], 2), 0.5)\n",
        "\n",
        "# Remove colunas que não serão mais utilizadas.\n",
        "df1 = df1.drop([\"OrderDate\", \"Date\", \"XShippingDistance\", \"YShippingDistance\"], axis=1)\n",
        "\n",
        "# Mostra as 5 primeiras linhas do dataset.\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2959455c",
      "metadata": {
        "id": "2959455c"
      },
      "source": [
        "4. Execute a célula de código abaixo para criar a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$. Além disso, o conjunto total de dados é separado em conjuntos de treinamento e validação e, na sequência, eles são padronizados.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ A primeira linha de comando remove da matriz de atributos a coluna `ExpectedShippingDays`, pois ela será nosso rótulo.\n",
        "+ A segunda linha cria o vetor de rótulos contendo apenas a coluna `ExpectedShippingDays`.\n",
        "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bddbd263",
      "metadata": {
        "id": "bddbd263"
      },
      "outputs": [],
      "source": [
        "# Matriz de atributos.\n",
        "X = df1.drop(['ExpectedShippingDays'], axis=1).to_numpy()\n",
        "\n",
        "# Rótulos.\n",
        "y = df1['ExpectedShippingDays'].to_numpy()\n",
        "\n",
        "# Separa conjunto de dados em conjuntos de treinamento e validação.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
        "\n",
        "# Instancia um padronizador.\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Normalize os conjuntos de dados.\n",
        "X_train = scaler.fit_transform(X_train) # Os parâmetros para a padronização são encontrados baseando-se no conjunto de treinamento.\n",
        "X_test = scaler.transform(X_test)       # O conjunto de teste (ou validação) é padronizado com os parâmetros encontrados com o conjunto de treinamento.\n",
        "\n",
        "# Imprime o tamanho dos conjuntos de treinamento e validação.\n",
        "print('Tamanho do conjunto de treinamento:', len(y_train))\n",
        "print('Tamanho do conjunto de validação:', len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e83649a1",
      "metadata": {
        "id": "e83649a1"
      },
      "source": [
        "5. Neste item, iremos treinar e verificar o erro quadrático médio (MSE) cometido por um **regressor linear** na tarefa de estimar o tempo estimado de chegada de uma remessa. Treine o modelo de regressão linear com o conjunto de treinamento, calcule e imprima o erro quadrático médio cometido pelo modelo para os conjuntos de treinamento e validação.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Instancie e treine um objeto da classe `LinearRegression`. A classe já foi importada durante a execução do item 1 deste exercício.\n",
        "+ Não é necessário usar a classe `PolynomialFeatures`, ou seja, não usaremos polinômios, apenas funções com formato de hiperplano.\n",
        "+ Também não é necessário escalonar (padronizar ou normalizar) os atributos, pois isto é feito no item anterior.\n",
        "+ Para calcular os erros cometidos com os conjuntos de treinamento e validação, use a função `mean_squared_error`, a qual foi importada durante a execução da célula de código do item 1 deste exercício."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a5ae53",
      "metadata": {
        "id": "58a5ae53"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d2dc1f",
      "metadata": {
        "id": "b5d2dc1f"
      },
      "source": [
        "6. Plote o histograma do erro entre os valores preditos pelo modelo de regresão linear (`LinearRegression`) treinado no item 5 e os rótulos para o **conjunto de validação**. Em seguida, imprima a média, variância e desvio padrão do erro entre os valores preditos pelo modelo e os rótulos.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Use o **conjunto de validação** para plotar o histograma.\n",
        "+ Use a função `hist` da biblioteca Matplotlib. Configure o parâmetro `bins` da função com o valor 100, ou seja, `bins=100`.\n",
        "+ Configure os limites do eixo `x` do histograma entre -8 e 8. Para isso uso a instrução:\n",
        "```python\n",
        "plt.xlim([-8, 8])\n",
        "```\n",
        "+ Configure os limites do eixo `y` do histograma entre 0 e 200. Para isso uso a instrução:\n",
        "```python\n",
        "plt.ylim([0, 200])\n",
        "```\n",
        "+ A documentação da função `hist` pode ser encontrada em:\n",
        "https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [linear_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/regressão/linear_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad75d7b",
      "metadata": {
        "id": "0ad75d7b"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e94fa0",
      "metadata": {
        "id": "65e94fa0"
      },
      "source": [
        "7. Agora, vamos usar busca exaustiva (`GridSearchCV`) e o **conjunto de treinamento** para encontrar os melhores valores de alguns parâmetros de uma rede `MLPRegressor` de tal forma que ela apresente o menor erro possível.\n",
        "\n",
        "O objeto da classe `GridSearchCV` automatiza o processo de busca pelo melhor conjunto de parâmetros de um modelo, neste caso, os parâmetros do objeto da classe `MLPRegressor`, mas poderia ser de qualquer outro modelo que necessite de ajuste fino de seus parâmetros. O dicionário de parâmetros, chamado no código de exemplo de `parameters`, que é passado para o `GridSearchCV` contém os parâmetros do objeto da classe `MLPRegressor` que desejamos testar e verificar qual combinação deles resulta no melhor resultado. Portanto, o `GridSearchCV` automatiza os testes que vão descobrir dentre esses valores do dicionário `parameters` quais são os melhores para cada parâmetro. Portanto, o que o `GridSearchCV` faz é configurar o objeto da classe `MLPRegressor` com todas as combinações possíveis dos parâmetros passados no dicionário `parameters` e retornar, ao final, a melhor combinação destes parâmetros.\n",
        "\n",
        "**OBS**.: Ao final do grid search, o objeto da classe `GridSearchCV` retreina o modelo com os melhores valores encontrados. Portanto, não é necessário instanciar-se um novo objeto e configurá-lo, basta usar o método `predict` do objeto da classe `GridSearchCV`.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Ao instanciar o objeto da classe `MLPRegressor` configure os parâmetros de entrada `max_iter` com o valor `5000` e o parâmetro `random_state` com a variável `seed`, definida no item 1 deste exercício.\n",
        "+ Use **grid search** (`GridSearchCV`) para encontrar: (i) o número ideal de nós, (ii) a função de ativação ideal dos nós e (iii) o melhor otimizador.\n",
        "+ O `GridSearchCV` deve testar o seguinte conjunto de parâmetros e valores:\n",
        "    * `'hidden_layer_sizes'` com os valores `(18,9)`, `(36,18)` e `(72,36)`.\n",
        "    * `'activation'` com os valores `tanh`, `'logistic'` e `'relu'`.\n",
        "    * `'solver'`  com os valores `adam` e `sgd`.\n",
        "+ Ao instanciar o objeto da classe `GridSearchCV`, configure-o com os seguintes parâmetros:\n",
        "    * número de *folds* para o k-Fold igual a 10, ou seja, `cv=10`.\n",
        "    * erro quadrático médio como sendo a estratégia para avaliar o desempenho do modelo, ou seja, `scoring='neg_mean_squared_error'`.\n",
        "    * usar todos os processadores disponíveis para acelerar a validação cruzada do modelo, ou seja, `n_jobs=-1`.\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb).\n",
        "+ **O treinamento será demorado, então pegue um café e tenha paciência.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c2995c7",
      "metadata": {
        "id": "2c2995c7"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e20621f",
      "metadata": {
        "id": "5e20621f"
      },
      "source": [
        "8. Após o treinamento, imprima quais foram os melhores valores encontrados pelo grid search.\n",
        "\n",
        "**DICAS**:\n",
        "    \n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ed34dc",
      "metadata": {
        "id": "84ed34dc"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d37ec46",
      "metadata": {
        "id": "7d37ec46"
      },
      "source": [
        "9. Qual é o erro quadrático médio da rede MLP para os conjuntos de treinamento e validação?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71c606f",
      "metadata": {
        "id": "d71c606f"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e18b0ab",
      "metadata": {
        "id": "9e18b0ab"
      },
      "source": [
        "10. Plote o histograma do erro entre os valores preditos pelo modelo MLP treinado no item 7 e os rótulos para o **conjunto de validação**. Em seguida, imprima a média, variância e desvio padrão do erro entre os valores preditos pelo modelo e os rótulos.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Use o **conjunto de validação** para plotar o histograma.\n",
        "+ Use a função `hist` da biblioteca Matplotlib. Configure o parâmetro `bins` da função com o valor 100, ou seja, `bins=100`.\n",
        "+ Configure os limites do eixo `x` do histograma entre -8 e 8. Para isso uso a instrução:\n",
        "```python\n",
        "plt.xlim([-8, 8])\n",
        "```\n",
        "+ Configure os limites do eixo `y` do histograma entre 0 e 200. Para isso uso a instrução:\n",
        "```python\n",
        "plt.ylim([0, 200])\n",
        "```\n",
        "+ A documentação da função `hist` pode ser encontrada em:\n",
        "https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [linear_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/regressão/linear_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bc40f2b",
      "metadata": {
        "id": "8bc40f2b"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7450dc01",
      "metadata": {
        "id": "7450dc01"
      },
      "source": [
        "11. Neste item, você deve comparar os histogramas, médias, variâncias e desvios padrão do erros de predição cometidos pelos dois modelos (i.e., regressor linear e rede MLP) e, na sequência, responder:\n",
        "\n",
        "+ Dado que um modelo de regressão perfeito, ou seja, um modelo que não comete nenhum erro, teria um histograma com todo os valores centrados em zero (neste caso, a média, variância e desvio padrão seriam iguais a 0), qual é o melhor modelo de regressão?\n",
        "    + Qual modelo apresenta o menor desvio padrão e, consequentemente, na média, o menor erro em relação ao valor esperado?\n",
        "\n",
        "**Justifique todas as respostas.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a422ea6",
      "metadata": {
        "id": "6a422ea6"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4ddadc",
      "metadata": {
        "id": "be4ddadc"
      },
      "source": [
        "### 4) Exercício sobre comparação de diferentes tipos de classificadores.\n",
        "\n",
        "Neste exercício, iremos comparar o desempenho de classificadores baseados no regressor logístico e em redes MLP na tarefa de predição de falhas.\n",
        "\n",
        "Você assumirá o papel de analista de negócios atribuído a uma equipe de manutenção de uma grande organização de manufatura. Sua equipe de manutenção pediu a você, como analista de negócios, para ajudar na previsão de falhas comuns. Eles forneceram a você um conjunto de dados históricos que contém características vinculadas a um determinado tipo de falha e gostariam que você previsse qual falha ocorrerá no futuro. Os tipos de falha incluem `No Failure`, `Overstrain` and `Power Failures` (i.e., Sem Falha, Sobretensão e Falhas de Energia, respectivamente).\n",
        "\n",
        "O conjunto de dados que usaremos neste exercício vem do \"Conjunto de dados de manutenção preditiva AI4I 2020\" (disponível no UCI Machine Learning Repository - Dua, D. e Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.)\n",
        "\n",
        "As colunas e seus respectivos tipos e descrições estão listadas abaixo.\n",
        "\n",
        "|     **Nome da coluna**     | **Tipo do dado** |                                                                  **Descrição**                                                                 |\n",
        "|:-----------------------:|:-------------:|:------------------------------------------------------------------------------------------------------------------------------------------------:|\n",
        "|           UID           |      INT      |                                                     unique identifier ranging from 1 to 10000                                                    |\n",
        "|        product_ID        |     STRING    |           consisting of a letter L, M, or H for low, medium, and high as product quality variants and a variant-specific serial number           |\n",
        "|           type          |     STRING    |                                      initial letter associated with productID consisting on L, M, or H only                                      |\n",
        "|   Air_Temperature [K]   |    DECIMAL    |                                                        air temperature specified in kelvin                                                       |\n",
        "| Process_Temperature_K_ |    DECIMAL    |                        precisely controlled temperatures to ensure quality of a given type of product specified in kelvin                        |\n",
        "|  Rotational_speed_rpm_ |    DECIMAL    | rotational speed, of an object rotating around an axis is the number of turns of the object divided by time, specified as revolutions per minute |\n",
        "|       Torque_Nm_       |    DECIMAL    |                                        machine turning force through a radius, expressed in newton meters                                        |\n",
        "|     Tool_wear_min_     |      INT      |                                                          tool wear expressed in minutes                                                          |\n",
        "|                         |                |                  **Rótulo**                                                              |\n",
        "|  Failure_Type  |     STRING    |                                                 No Failure, Power Failure, or Overstrain Failure                                                 |\n",
        "\n",
        "\n",
        "#### Referências\n",
        "\n",
        "[1] 'AI4I 2020 Predictive Maintenance Dataset', https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset\n",
        "\n",
        "[2] 'Predicting Machine Failure Types (Manufacturing)', https://catalog.workshops.aws/canvas-immersion-day/en-US/1-use-cases/6-manufacturing\n",
        "\n",
        "[3] '97% Accuracy along with EDA and UP Sampling', https://www.kaggle.com/code/durgancegaur/97-accuracy-along-with-eda-and-up-sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a09317",
      "metadata": {
        "id": "92a09317"
      },
      "source": [
        "1. Execute a célula de código abaixo para importar as bibliotecas necessárias e carregar a base de dados. Analise as cinco primeiras linhas da base de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4cf0d3b",
      "metadata": {
        "id": "e4cf0d3b"
      },
      "outputs": [],
      "source": [
        "# Importando as bibliotecas necessárias.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import seaborn as sns\n",
        "import urllib\n",
        "\n",
        "# Semente usada para resetar geradores de sequência PN.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Baixa as bases de dados do dropbox.\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/8azx0mjvv246mjm/maintenance_dataset.csv?dl=1', 'maintenance_dataset.csv')\n",
        "\n",
        "# Carrega o banco de dados.\n",
        "df = pd.read_csv('./maintenance_dataset.csv')\n",
        "\n",
        "# Apresenta as cinco primeiras linhas do banco de dados.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1fe9b50",
      "metadata": {
        "id": "d1fe9b50"
      },
      "source": [
        "2. Execute a célula de código abaixo para verificar a existência de valores nulos e duplicados e remover colunas inúteis.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para limpar a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49320ed2",
      "metadata": {
        "id": "49320ed2"
      },
      "outputs": [],
      "source": [
        "# Verificando a existência de valores duplicados.\n",
        "N_null = sum(df.isnull().sum())\n",
        "print(\"O dataset contém {} valores nulos\".format(N_null))\n",
        "\n",
        "# Removendo valores duplicados.\n",
        "N_dupli = sum(df.duplicated(keep='first'))\n",
        "dataset = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
        "print(\"O dataset contém {} valores duplicados\".format(N_dupli))\n",
        "\n",
        "# Removendo colunas que não trazem informação útil para o problema.\n",
        "df1 = df.drop([\"UDI\", \"Product_ID\"],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc2cd9b",
      "metadata": {
        "id": "fcc2cd9b"
      },
      "source": [
        "3. Execute a célula abaixo para realizar a engenharia de atributos da base de dados.\n",
        "\n",
        "A engenharia de atributos é o processo de transformar os atributos em um formato adequado para o modelo de aprendizado de máquina. Neste exercício, precisamos transformar variáveis categóricas.\n",
        "\n",
        "A maioria dos algoritmos de aprendizado de máquina requer valores numéricos. Portanto, todos os atributos categóricos (strings) disponíveis no conjunto de dados devem ser codificados em rótulos numéricos antes de treinarmos um modelo.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os comentários abaixo explicam cada uma das instruções para realizar a engenharia de atributos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b406cd",
      "metadata": {
        "id": "24b406cd"
      },
      "outputs": [],
      "source": [
        "# Converte colunas categóricas em colunas numéricas com valores começando de 1.\n",
        "encoder = ce.OrdinalEncoder(cols=['Type', 'Failure_Type'])\n",
        "df1 = encoder.fit_transform(df1)\n",
        "\n",
        "# Converte valores numéricos que se iniciam em 1 em valores que se iniciam em 0. Assim, os rótulos das classes começam em 0.\n",
        "scaler = LabelEncoder()\n",
        "df1['Failure_Type'] = scaler.fit_transform(df1['Failure_Type'])\n",
        "\n",
        "# Mostra as 5 primeiras linhas do dataset.\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04963e6",
      "metadata": {
        "id": "e04963e6"
      },
      "source": [
        "4. Execute a célula de código abaixo para criar a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ A primeira linha de comando remove da matriz de atributos a coluna `Failure_Type`, pois ela será nosso rótulo.\n",
        "+ A segunda linha cria o vetor de rótulos contendo apenas a coluna `Failure_Type`.\n",
        "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e84d4de1",
      "metadata": {
        "id": "e84d4de1"
      },
      "outputs": [],
      "source": [
        "# Criando o conjunto de pares de treinamento, X e y.\n",
        "X = df1.drop(columns=\"Failure_Type\", axis=1).to_numpy()\n",
        "y = df1[\"Failure_Type\"].to_numpy()\n",
        "\n",
        "# Atributos.\n",
        "print('Dimensão da matriz de atributos:', X.shape)\n",
        "# Rótulos.\n",
        "print('Dimensão do vetor de rótulos:', y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fff865d1",
      "metadata": {
        "id": "fff865d1"
      },
      "source": [
        "5. Execute a célula de código abaixo e analise a quantidade de exemplos de cada classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a4881e",
      "metadata": {
        "id": "27a4881e"
      },
      "outputs": [],
      "source": [
        "# Plota histograma com a quantidade de exemplos por classe.\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(['No failure', 'Power Failure', 'Overstrain Failure'], [len(y[y==0]), len(y[y==1]), len(y[y==2])])\n",
        "ax.bar_label(bars)\n",
        "plt.xlabel('Classes', fontsize=12)\n",
        "plt.ylabel('Quantidade de exemplos de cada classe', fontsize=12)\n",
        "plt.ylim([1, 10000])\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4686acd",
      "metadata": {
        "id": "e4686acd"
      },
      "source": [
        "6. Após ter analisado a quantidade de exemplos em cada uma das três classes no item anterior, o que se pode concluir sobre elas?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb20f85e",
      "metadata": {
        "id": "cb20f85e"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c2db71c",
      "metadata": {
        "id": "3c2db71c"
      },
      "source": [
        "7. Lidar com um problema desbalanceado, ou seja, em que as classes têm uma grande discrepância em termos de número de amostras, pode ser um desafio. Portanto, é importante adotar estratégias adequadas para criar conjuntos de treinamento e validação que tenham uma boa proporção entre as classes.\n",
        "\n",
        "A reamostragem é uma estratégia que envolve a manipulação do conjunto de dados original para criar um equilíbrio entre as classes. Duas abordagens comuns são o oversampling (aumentar as amostras da classe minoritária) e o undersampling (reduzir as amostras da classe majoritária).\n",
        "\n",
        "A biblioteca `imbalanced-learn` oferece uma série de métodos para realizar essas técnicas, como RandomOverSampler e RandomUnderSampler.\n",
        "\n",
        "Neste item, usaremos a estratégia do oversampling aleatório que seleciona aleatoriamente uma quantidade específica de amostras das classes minoritárias e os duplica para equilibrar a distribuição de classes em um conjunto de dados desbalanceado. Essa replicação é feita sem levar em consideração a estrutura dos dados ou a relação entre os exemplos. Os exemplos são escolhidos de forma independente um do outro. O oversampling não altera os exemplos da classe majoritária, apenas das classes minoritárias.\n",
        "\n",
        "O oversampling aleatório é uma técnica simples e fácil de implementar, pois não requer cálculos complexos ou algoritmos adicionais. No entanto, ele pode levar ao *overfitting* do modelo, uma vez que os exemplos das classes minoritárias são duplicados diretamente, aumentando sua influência no modelo de aprendizado de máquina.\n",
        "\n",
        "Em geral, não há uma abordagem única que funcione melhor para todos os casos. Recomenda-se experimentar diferentes técnicas e avaliar os resultados com base nas métricas relevantes para o problema específico.\n",
        "\n",
        "Execute a célula de código abaixo. Ela aplica a estratégia do oversampling, aumentando o número de amostras das classes minoritárias, plota o histograma com a quantidade de amostras de cada classe após o oversampling, divide o conjunto total de amostras em conjuntos de treinamento e validação e, ao final, normaliza os conjuntos.\n",
        "\n",
        "**OBS**.: O novo conjunto de dados já está dividido em conjuntos **normalizados** de treinamento e validação.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Os novos conjuntos normalizados de treinamento e validação são dados por `X_train/y_train` e `X_test/y_test`, respectivamente.\n",
        "\n",
        "#### Referências\n",
        "\n",
        "[1] 'A Gentle Introduction to Imbalanced Classification', https://machinelearningmastery.com/what-is-imbalanced-classification/\n",
        "\n",
        "[2] '8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset', https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "\n",
        "[3] 'Solving The Class Imbalance Problem', https://towardsdatascience.com/solving-the-class-imbalance-problem-58cb926b5a0f\n",
        "\n",
        "[4] 'Imbalanced Data : How to handle Imbalanced Classification Problems', https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200af53f",
      "metadata": {
        "id": "200af53f"
      },
      "outputs": [],
      "source": [
        "# Instancia um objeto de oversampling aleatório.\n",
        "ros = RandomOverSampler(sampling_strategy='not majority', random_state=seed)\n",
        "\n",
        "# Aplica o oversampling aleatório ao conjunto desbalanceado.\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "# Plota histograma com a quantidade de exemplos por classe.\n",
        "fig, ax = plt.subplots()\n",
        "bars = ax.bar(['No failure', 'Power Failure', 'Overstrain Failure'], [len(y_resampled[y_resampled==0]), len(y_resampled[y_resampled==1]), len(y_resampled[y_resampled==2])])\n",
        "ax.bar_label(bars)\n",
        "plt.xlabel('Classes', fontsize=12)\n",
        "plt.ylabel('Quantidade de exemplos de cada classe', fontsize=12)\n",
        "plt.ylim([1, 10000])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Divide o conjunto total de dados em conjuntos de treinamento e validação.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=seed)\n",
        "\n",
        "# Instancia um padronizador.\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize os conjuntos de dados.\n",
        "X_train = scaler.fit_transform(X_train) # Os parâmetros para a normalização são encontrados baseando-se no conjunto de treinamento.\n",
        "X_test = scaler.transform(X_test)       # O conjunto de teste (ou validação) é normalizado com os parâmetros encontrados com o conjunto de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e890d0bc",
      "metadata": {
        "id": "e890d0bc"
      },
      "source": [
        "8. Analise a figura acima e responda:\n",
        "\n",
        "+ O que ocorreu com a quantidade de amostras das três classes?\n",
        "\n",
        "(**Justifique sua resposta**).\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Verifique o número de amostras das três classes no item 5."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "690c2fce",
      "metadata": {
        "id": "690c2fce"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663df0b4",
      "metadata": {
        "id": "663df0b4"
      },
      "source": [
        "9. Agora, vamos usar busca exaustiva (`GridSearchCV`) e o **conjunto de treinamento** para encontrar os valores ideais para alguns dos parâmetros de um objeto da classe `LogisticRegression` de tal forma que o modelo classifique da melhor forma possível as três classes.\n",
        "\n",
        "O objeto da classe `GridSearchCV` automatiza o processo de busca pelo melhor conjunto de parâmetros de um modelo, neste caso, os parâmetros do objeto da classe `LogisticRegression`, mas poderia ser de qualquer outro modelo que necessite de ajuste fino de seus parâmetros. O dicionário de parâmetros, chamado no código de exemplo de `parameters`, que é passado para o `GridSearchCV` contém os parâmetros do objeto da classe `LogisticRegression` que desejamos testar e verificar qual combinação deles resulta no melhor resultado. Portanto, o `GridSearchCV` automatiza os testes que vão descobrir dentre esses valores do dicionário `parameters` quais são os melhores para cada parâmetro. Portanto, o que o `GridSearchCV` faz é configurar o objeto da classe `LogisticRegression` com todas as combinações possíveis dos parâmetros passados no dicionário `parameters` e retornar, ao final, a melhor combinação destes parâmetros.\n",
        "\n",
        "**OBS**.: Ao final do grid search, o objeto da classe `GridSearchCV` retreina o modelo com os melhores valores encontrados. Portanto, não é necessário instanciar-se um novo objeto e configurá-lo, basta usar o método `predict` do objeto da classe `GridSearchCV`.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Ao instanciar o objeto da classe `LogisticRegression` configure os parâmetros de entrada `penalty` com o valor `None`, ou seja, `penalty=None`, `random_state` com a variável `seed` definida no item 1 deste exercício, ou seja, `random_state=seed` e `n_jobs` com o valor `-1`, ou seja, `n_jobs=-1` (habilita o uso de todos os processadores disponíveis para acelerar o treinamento).\n",
        "+ Use **grid search** (`GridSearchCV`) para encontrar: (i) o melhor otimizador e (ii) a melhor abordagem de classificação.\n",
        "+ O `GridSearchCV` deve testar o  seguinte conjunto de parâmetros e valores:\n",
        "    * `'solver'` com as strings `'lbfgs'`, `'newton-cg'`, `'sag'` e `'saga'`.\n",
        "    * `'multi_class'` com as strings `'ovr'` e `'multinomial'`.\n",
        "+ Ao instanciar o objeto da classe `GridSearchCV`, configure-o com os seguintes parâmetros:\n",
        "    * número de *folds* para o k-Fold igual a 10, ou seja, `cv=10`.\n",
        "    * acurácia como sendo a estratégia para avaliar o desempenho do modelo, ou seja, `scoring='accuracy'`.\n",
        "    * usar todos os processadores disponíveis para acelerar a validação cruzada do modelo, ou seja, `n_jobs=-1`.\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb). Só não se esqueça que você deve usar a classe `LogisticRegression` ou invés da `MLPRegressor` que está sendo usada no exemplo.\n",
        "+ **O treinamento pode ser um pouco demorado, então pegue um café e tenha paciência**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb0da0c",
      "metadata": {
        "id": "0bb0da0c"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4dede6b",
      "metadata": {
        "id": "d4dede6b"
      },
      "source": [
        "10. Após o treinamento, imprima quais foram os melhores valores encontrados pela busca exaustiva, ou seja, o *grid search*.\n",
        "\n",
        "**DICAS**:\n",
        "    \n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c73025",
      "metadata": {
        "id": "99c73025"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bf07fe1",
      "metadata": {
        "id": "5bf07fe1"
      },
      "source": [
        "11. Usando o melhor modelo baseado no regressão logistica encontrado no item 9, calcule a imprima as acurácias para os conjuntos de treinamento e validação.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Lembre-se que ao final do grid search, o objeto da classe `GridSearchCV` retreina o modelo com os melhores valores encontrados. Portanto, não é necessário instanciar-se um novo objeto e configurá-lo, basta usar o método `predict` do objeto da classe `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0307e17e",
      "metadata": {
        "id": "0307e17e"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f87ce8",
      "metadata": {
        "id": "97f87ce8"
      },
      "source": [
        "12. Plote a matriz de confusão do modelo para os exemplos do **conjunto de validação**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_metrics.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/perceptron/perceptron_xor_problem.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab5407c",
      "metadata": {
        "id": "6ab5407c"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff569772",
      "metadata": {
        "id": "ff569772"
      },
      "source": [
        "13. Use a função `classification_report` da biblioteca SciKit-Learn para imprimir algumas das métricas de classificação para o **conjunto de validação**.\n",
        "\n",
        "**OBS**.: Configure o parâmetro `digits` da função `classification_report` com o valor 4, ou seja, a função irá imprimir as métricas com 4 casas decimais.\n",
        "```python\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "```\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_with_cross_validation.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classificação/classification_with_cross_validation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffa0e579",
      "metadata": {
        "id": "ffa0e579"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1307b7bb",
      "metadata": {
        "id": "1307b7bb"
      },
      "source": [
        "14. Use busca exaustiva (`GridSearchCV`) e o **conjunto de treinamento** para encontrar os valores ideais para alguns dos parâmetros de um objeto da classe `MLPClassifier` de tal forma que o modelo classifique o melhor possível as três classes.\n",
        "\n",
        "O objeto da classe `GridSearchCV` automatiza o processo de busca pelo melhor conjunto de parâmetros de um modelo, neste caso, os parâmetros do objeto da classe `MLPClassifier`, mas poderia ser de qualquer outro modelo que necessite de ajuste fino de seus parâmetros. O dicionário de parâmetros, chamado no código de exemplo de `parameters`, que é passado para o `GridSearchCV` contém os parâmetros do objeto da classe `MLPClassifier` que desejamos testar e verificar qual combinação deles resulta no melhor resultado. Portanto, o `GridSearchCV` automatiza os testes que vão descobrir dentre esses valores do dicionário `parameters` quais são os melhores para cada parâmetro. Portanto, o que o `GridSearchCV` faz é configurar o objeto da classe `MLPClassifier` com todas as combinações possíveis dos parâmetros passados no dicionário `parameters` e retornar, ao final, a melhor combinação destes parâmetros.\n",
        "\n",
        "**OBS**.: Ao final do grid search, o objeto da classe `GridSearchCV` retreina o modelo com os melhores valores encontrados. Portanto, não é necessário instanciar-se um novo objeto e configurá-lo, basta usar o método `predict` do objeto da classe `GridSearchCV`.\n",
        "\n",
        "**DICAS**:\n",
        "\n",
        "+ Ao instanciar o objeto da classe `MLPClassifier` configure os parâmetros de entrada `max_iter` com o valor `10000`, ou seja, `max_iter=10000` e `random_state` com a variável `seed` definida no item 1 deste exercício, ou seja, `random_state=seed`.\n",
        "+ Use **grid search** (`GridSearchCV`) para encontrar: (i) o número ideal de nós e camadas escondidas, (ii) a função de ativação ideal dos nós e (iii) o melhor otimizador.\n",
        "+ O `GridSearchCV` deve testar o  seguinte conjunto de parâmetros e valores:\n",
        "    * `'hidden_layer_sizes'` com as tuplas `(6,)`, `(3,)`, `(6,3)`, `(12,6,3)`,e `(24,12,6,3)`.\n",
        "    * `'activation'` com as strings `'logistic'`, `tanh`, e `'relu'`.\n",
        "    * `'solver'` com as strings `sgd`, `'lbfgs'` e `'adam'`.\n",
        "+ Ao instanciar o objeto da classe `GridSearchCV`, configure-o com os seguintes parâmetros:\n",
        "    * número de *folds* para o k-Fold igual a 10, ou seja, `cv=10`.\n",
        "    * acurácia como sendo a estratégia para avaliar o desempenho do modelo, ou seja, `scoring='accuracy'`.\n",
        "    * usar todos os processadores disponíveis para acelerar a validação cruzada do modelo, ou seja, `n_jobs=-1`.\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb). Só não se esqueça que você deve usar a classe `MLPClassifier` ou invés da `MLPRegressor` que está sendo usada no exemplo.\n",
        "+ **O treinamento pode ser um pouco demorado, então pegue um café e tenha paciência**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f81972e8",
      "metadata": {
        "id": "f81972e8"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a10005",
      "metadata": {
        "id": "c4a10005"
      },
      "source": [
        "15. Após o treinamento, imprima quais foram os melhores valores encontrados pela busca exaustiva, ou seja, o *grid search*.\n",
        "\n",
        "**DICAS**:\n",
        "    \n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [function_approximation_regression.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/mlp/function_approximation_regression.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e25673e",
      "metadata": {
        "id": "7e25673e"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c60a5ed",
      "metadata": {
        "id": "9c60a5ed"
      },
      "source": [
        "16. Usando o melhor modelo baseado na rede MLP encontrado no item 14, calcule a imprima as acurácias para os conjuntos de treinamento e validação.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Lembre-se que ao final do grid search, o objeto da classe `GridSearchCV` retreina o modelo com os melhores valores encontrados. Portanto, não é necessário instanciar-se um novo objeto e configurá-lo, basta usar o método `predict` do objeto da classe `GridSearchCV`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5183b91",
      "metadata": {
        "id": "e5183b91"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37d38a4",
      "metadata": {
        "id": "d37d38a4"
      },
      "source": [
        "17. Plote a matriz de confusão do modelo para os exemplos do **conjunto de validação**.\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_metrics.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/perceptron/perceptron_xor_problem.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12373abf",
      "metadata": {
        "id": "12373abf"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017fb9af",
      "metadata": {
        "id": "017fb9af"
      },
      "source": [
        "18. Use a função `classification_report` da biblioteca SciKit-Learn para imprimir algumas das métricas de classificação para o **conjunto de validação**.\n",
        "\n",
        "**OBS**.: Configure o parâmetro `digits` da função `classification_report` com o valor 4, ou seja, a função irá imprimir as métricas com 4 casas decimais. veja o exemplo abaixo.\n",
        "```python\n",
        "print(classification_report(y_test, y_pred, digits=4))\n",
        "```\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ Para ajudar a resolver este item, veja o seguinte exemplo: [classification_with_cross_validation.ipynb](https://colab.research.google.com/github/zz4fap/t320_aprendizado_de_maquina/blob/main/notebooks/classificação/classification_with_cross_validation.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56eb4ce7",
      "metadata": {
        "id": "56eb4ce7"
      },
      "outputs": [],
      "source": [
        "# Digite aqui o código do exercício."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53109391",
      "metadata": {
        "id": "53109391"
      },
      "source": [
        "19. Analise as matrizes de confusão e os reportes de métricas dos dois classificadores treinados neste exercício e responda:\n",
        "\n",
        "+ Qual dos dois classificadores tem o melhor desempenho?\n",
        "+ Podemos usar apenas a acurácia para decidir qual é o melhor classificador (lembre-se que balanceamos as classes)?\n",
        "\n",
        "**Justifique suas respostas**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5c274b",
      "metadata": {
        "id": "6b5c274b"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Escreva abaixo a resposta do exercício.</span>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}