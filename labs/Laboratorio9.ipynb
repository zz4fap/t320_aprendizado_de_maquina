{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21HL_zD-Y2Ga"
   },
   "source": [
    "# Laboratório #9\n",
    "\n",
    "### Instruções\n",
    "\n",
    "1. Quando você terminar os exercícios do laboratório, vá ao menu do Jupyter ou Colab e selecione a opção para fazer download do notebook.\n",
    "    * Os notebooks tem extensão .ipynb. \n",
    "    * Este deve ser o arquivo que você irá entregar.\n",
    "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
    "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
    "2. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este laboratório e faça o upload do seu notebook. Veja que há uma opção de anexar arquivos à tarefa.\n",
    "3. Não se esqueça de colocar seu **nome** e **matrícula** na célula de texto abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NvNE5VfY2Gk"
   },
   "source": [
    "**Nome**:\n",
    "\n",
    "**Matrícula**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-dKuPAoY2Gm"
   },
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nov-CJlfY2Gn"
   },
   "source": [
    "#### 1)  Neste exercício, você irá utilizar o tensorflow para criar uma rede neural para a classificação de objetos.\n",
    "\n",
    "Utilizaremos a base de dados conhecida como CIFAR10, a qual possui 50.000 32x32 imagens coloridas, ou seja, elas têm 3 dimensões, uma para cada uma das três cores, para treinamento e 10.000 32x32 imagens coloridas para validação. As imagens pertencem a 10 classes, as quais são listadas abaixo.\n",
    "\n",
    "| Rótulo |  Descrição |\n",
    "|:------:|:----------:|\n",
    "|    0   |  airplane  |\n",
    "|    1   | automobile |\n",
    "|    2   |    bird    |\n",
    "|    3   |     cat    |\n",
    "|    4   |    deer    |\n",
    "|    5   |     dog    |\n",
    "|    6   |    frog    |\n",
    "|    7   |    horse   |\n",
    "|    8   |    ship    |\n",
    "|    9   |    truck   |\n",
    "\n",
    "\n",
    "1. Execute a célula de código abaixo para baixar a base de dados e analise as imagens geradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "syIYbkj-Y2Go",
    "outputId": "0b296193-cae5-4041-e871-abca5275b2c6"
   },
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Bibliotecas Auxiliares\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download the dataset.\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Reshaping the label arrays.\n",
    "train_labels = train_labels.reshape(-1,)\n",
    "test_labels = test_labels.reshape(-1,)\n",
    "\n",
    "# Defining the class names.\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Showing the first 25 images.\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQbGRiJnY2Gs"
   },
   "source": [
    "2. Normalize os conjuntos de treinamento e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijEyDA4CY2Gt"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6YN2FyOY2Gu"
   },
   "source": [
    "3. Crie uma rede neural, usando a API `Sequential` do keras.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Lembre-se que as imagens têm as seguintes dimensões 32x32x3.\n",
    "+ Use o mesmo modelo do exemplo sobre Tensorflow, apenas mude as dimensões de entrada da camada de \"achatamento\".\n",
    "+ A camada `Flatten` espera como `input_shape` as dimensões exatas das imagens, ou seja, 32x32x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuavsTHqY2G5"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFLdKDZ_Y2G8"
   },
   "source": [
    "4. Compile o modelo.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Use a mesma configuração do exemplo sobre Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mz1zn8U2Y2G-"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tw1sRO6LY2G_"
   },
   "source": [
    "5. Treine o modelo por 25 épocas e armazene o histórico de valores da função de custo e da acurácia ao longo das épocas de treinamento. Após o treinamento, responda\n",
    "\n",
    "    1. Qual fui a acurácia atingida?\n",
    "    2. Ela poderia ser maior?\n",
    "    3. Como podemos aumentar a acurácia do modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_t484yjY2HA",
    "outputId": "a1ede5a7-93ec-4baa-dbc9-88e4ab7b92a7"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8SgWcqLY2HB"
   },
   "source": [
    "6. Execute o trecho de código abaixo para treinar um outro modelo mais adequado ao problema da classificação da base de dados CIFAR10. \n",
    "\n",
    "O modelo configurado abaixo é conhecido como VGG (Visual Geometry Group), também conhecido como VGGNet, uma arquitetura clássica de rede neural convolucional (CNN). O VGG foi desenvolvido para aumentar a profundidade de tais das redes convolutiocnais a fim de aumentar o desempenho do modelo. Para mais informações sobre esta rede, acesse: https://viso.ai/deep-learning/vgg-very-deep-convolutional-networks/\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Habilite o use de GPU para acelerar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oU11DiS9Y2HC",
    "outputId": "92a158be-efb9-4f76-fdf9-b6f133ddf5c8"
   },
   "outputs": [],
   "source": [
    "# Define VGG model.\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the defined model.\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the VGG model.\n",
    "history2 = model2.fit(train_images, train_labels, batch_size=64, validation_data=(test_images, test_labels), epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4l28-IXY2HG"
   },
   "source": [
    "7. Use as informações contidas no objeto do tipo `History` do segundo modelo para plotar uma figura do erro/acurácia em função das épocas de treinamento para os conjuntos de treinamento e validação.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ O objeto da classe `History` do segundo modelo armazena também as informações de loss e accuracy calculadas com o conjunto de validação. Para acessar os valores de loss do conjunto de validação, indexe o dicionário `history` com a chave `val_loss`. Para acessar os valores de acurácia do conjunto de validação, indexe o dicionário `history` com a chave `val_accuracy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "HMiASJPHY2HH",
    "outputId": "aaef62bb-667e-4f43-b9d7-51fc1a1b3dce"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNQWizKoeWdF"
   },
   "source": [
    "8. Analise o gráfico com os valores de *loss*. Comparando a curva para o conjunto de treinamento com a curva para o conjunto de validação, o que podemos concluir sobre o comportamento do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3Ne6oNLelxK"
   },
   "source": [
    "<span style=\"color:blue\">Escreva aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9hge4Te8aaYQ"
   },
   "source": [
    "9. Avalie a acurácia do segundo modelo no conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLrZ2ByRaZGk",
    "outputId": "90b4d087-757e-452c-ee6f-8a4f6d2a5cc0"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7AnlnVYay5C"
   },
   "source": [
    "10. Plote a matriz de confusão para o conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "S0R6hAglayHH",
    "outputId": "ee2a9f6d-526a-4314-ece7-caaa3ab74403"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVdBefTSggg7"
   },
   "source": [
    "11. O que poderia ser feito para melhorar o desempenho do segundo modelo no conjunto de validação?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAKboUwDgeSq"
   },
   "source": [
    "<span style=\"color:blue\">Escreva aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut8Bmsw7hJ46"
   },
   "source": [
    "12. Neste exercício iremos utilizar uma técnica de regularização conhecida como *dropout*. Execute a célula de código abaixo.\n",
    "\n",
    "Dropout é uma técnica simples que elimina nós aleatoriamente da rede. Ele tem um efeito de regularização, pois os nós restantes devem se adaptar para compensar a folga criada pelos nós removidos. O *dropout* é adicionado ao modelo como camadas chamadas *Dropout*.\n",
    "\n",
    "Para saber mais sobre esta técnica de regularização, acesse: https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyH5kyfyhJax",
    "outputId": "d7e8e7f5-0d94-4c79-c259-e82eef171360"
   },
   "outputs": [],
   "source": [
    "# Define VGG model com dropout.\n",
    "model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the defined model.\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the VGG model.\n",
    "history3 = model3.fit(train_images, train_labels, batch_size=64, validation_data=(test_images, test_labels), epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFR-WFgti0X3"
   },
   "source": [
    "13. Use as informações contidas no objeto do tipo `History` do terceiro modelo para plotar uma figura do erro/acurácia em função das épocas de treinamento para os conjuntos de treinamento e validação.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ O objeto da classe `History` do segundo modelo armazena também as informações de loss e accuracy calculadas com o conjunto de validação. Para acessar os valores de loss do conjunto de validação, indexe o dicionário `history` com a chave `val_loss`. Para acessar os valores de acurácia do conjunto de validação, indexe o dicionário `history` com a chave `val_accuracy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "W3gOqOMzi0zU",
    "outputId": "0cbde32e-3108-40b2-e237-9be28f86568e"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJvi4WC9kG0H"
   },
   "source": [
    "14. Analise o gráfico com os valores de *loss*. Comparando a curva para o conjunto de treinamento com a curva para o conjunto de validação, o que podemos concluir sobre o comportamento do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIeZDx_qkU8T"
   },
   "source": [
    "<span style=\"color:blue\">Escreva aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZdxOBsnk7e1"
   },
   "source": [
    "# Referência\n",
    "\n",
    "[1] Jason Brownlee, \"How to Develop a CNN From Scratch for CIFAR-10 Photo Classification\", https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Laboratorio9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
